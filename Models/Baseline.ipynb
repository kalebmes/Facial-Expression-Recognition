{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kalebmes/Facial-Expression-Recognition/blob/main/Models/Baseline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_hbOvpcyD-7H",
        "outputId": "ba8e89b1-1ff0-4d0e-d1fb-979b9ac6b22a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "#mount your drive first - you can do it once\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "1O_7o8yiL7fZ"
      },
      "outputs": [],
      "source": [
        "#importing necessary modules\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from PIL import Image\n",
        "import os\n",
        "import torchvision.datasets as dset\n",
        "import torchvision.transforms as T"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1AtbkaA7Ozsy",
        "outputId": "38a0b2cd-42f9-4057-d3ee-eb8322f361df"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU available\n"
          ]
        }
      ],
      "source": [
        "#hyperparameters start form \n",
        "lr = 1e-3\n",
        "batch_size = 128\n",
        "epochs = 50\n",
        "\n",
        "#device\n",
        "device = 'cpu'\n",
        "if torch.cuda.is_available():\n",
        "  device = 'cuda'\n",
        "  print('GPU available')\n",
        "else:\n",
        "  print('training is done on CPU')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "mDauIl3KPaE4"
      },
      "outputs": [],
      "source": [
        "#now let's load the dataset into the 'dataloader' package of pytorch\n",
        "from torchvision.datasets import ImageFolder\n",
        "import torchvision.transforms as T"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "3Mn5MAN8SsUR"
      },
      "outputs": [],
      "source": [
        "#first step is creating an augmentation cell using transforms of pytorch\n",
        "train_augs = T.Compose([T.RandomHorizontalFlip(p=0.5), \n",
        "                        T.RandomRotation(degrees=(-10, +10)),\n",
        "                        T.RandomAffine(degrees=(-10, +10), translate=(0.1, 0.2)),\n",
        "                        T.Resize((48, 48)),\n",
        "                        T.ToTensor()])\n",
        "\n",
        "valid_augs = T.Compose([T.ToTensor()])\n",
        "\n",
        "test_augs = T.Compose([T.ToTensor()])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "xJKiovhRb1Yz"
      },
      "outputs": [],
      "source": [
        "data_path = '/content/drive/MyDrive/datasets'\n",
        "train_path = os.path.join(data_path, 'train')\n",
        "validation_path = os.path.join(data_path, 'validation')\n",
        "test_path = os.path.join(data_path, 'test')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-iRhgKwIS3jX",
        "outputId": "dc87a9eb-c626-4003-8cfe-1881a926eedc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total no. of examples in trainset : 49297\n",
            "Total no. of examples in validset : 3599\n",
            "Total no. of examples in testset : 3589\n"
          ]
        }
      ],
      "source": [
        "trainset = ImageFolder(train_path, transform=train_augs)\n",
        "validset = ImageFolder(validation_path, transform=valid_augs)\n",
        "testset = ImageFolder(test_path, transform=test_augs)\n",
        "print(f\"Total no. of examples in trainset : {len(trainset)}\")\n",
        "print(f\"Total no. of examples in validset : {len(validset)}\")\n",
        "print(f\"Total no. of examples in testset : {len(testset)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SrM66qzviRg6",
        "outputId": "87d4a85c-b288-46da-8bbb-24f6d751a2fe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'anger': 0, 'disgust': 1, 'fear': 2, 'happy': 3, 'neutral': 4, 'sad': 5, 'surprise': 6}\n"
          ]
        }
      ],
      "source": [
        "print(trainset.class_to_idx)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316
        },
        "id": "4KPvBCwgiWqI",
        "outputId": "26ebf280-b8d6-49d6-f3e4-49383023b1f8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "chosen index:  10502\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, '1')"
            ]
          },
          "metadata": {},
          "execution_count": 9
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAEICAYAAACZA4KlAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO2daZBdZ3nn/8/db+/qfdNqSzY2BssIg21mQkyYgO3BrkCxFFAO4ynzYaiCIlWJk0nNVKpSUzA1FeBDCOXCDK4kg2FYgsdVARvHxNgJtoVtiCXZkixraanV3er99u27v/Ohr2w9i9TXWm63OM+vyuV+Tz/nnPecc997+vnrWSiEAMdxfvuJrfUEHMdpDr7YHSci+GJ3nIjgi91xIoIvdseJCL7YHSci+GJ3nIjgi91RENHniGg3ERWJ6NtrPR/n4pBY6wk465ITAP4SwO8DyK7xXJyLhC92RxFC+CEAENEuAKNrPB3nIuF/xjtORPDF7jgRwRe740QEX+yOExFcoHMURJTAymcjDiBORBkAlRBCZW1n5lwI/mZ3LP4cwDKA+wB8qv7zn6/pjJwLhrx4heNEA3+zO05E8MXuOBHBF7vjRIQLWuxE9AEieoWIDhLRfRdrUo7jXHzOW6AjojiA/QDeD2AMwHMAPhFC2HuOfVwNdJxLTAiBrO0X8ma/EcDBEMKhEEIJwEMA7ryA4zmOcwm5kMU+AuDYGeOx+jbHcdYhlzyCjojuBXDvpT6P4zjn5kIW+3EAG88Yj9a3MUII9wO4H3Cf3XHWkgv5M/45ANuJaCsRpQB8HMDDF2dajuNcbM77zR5CqBDR5wD8FCsJE98KIey5aDNzHOei0tTYeP8z3nEuPZfin94cx7mM8Hx2x6lDpF+IFOPvw1jMeD+K/ZKplDLJtLaec2ydK5VOK5vJo0fZOL+4qOdzFvzN7jgRwRe740QEX+yOExF8sTtORHCBzjknpiDVgE0mw0WqdCqpbFpaMnyD8c/Ara28+1RXhxa2ujd0sPHhQ8eUzYnpOTaOt3Uomy1v26W2ffAP7mLjTFubsqnF42zc0d+nbNq6u9k4266PI+9jjPR9/Z+f+Qwb/+pnP1M2Z8Pf7I4TEXyxO05E8MXuOBHBffY1JJGIq23JJH8k2WxG2XQIf6+lRXdV7unpYuOB/l5l09fH/ciR4X5l09/XpbaVy2U27u1pVzYDfXxbe5v22dvb+LzJePdIv741rQNWkgl+z147qJIv8fVvfp+Nnz4wrmyqcf08BnZcy8bXv/Mder8UP3/FiAqvicCbhuLGazW1qXfz5kb2NPE3u+NEBF/sjhMRfLE7TkTwxe44EeG3RqCTGUvxhL40mY1kZSdVCiV+nJjOhGoRASMbR7WwdfO/e6fatnnzEBsPCIEMAHq7ebBHX48O/tjQyYWtbEZfa1srF7bSSW0TT/Bri8W0IARUjW3ynlj7iW2hbNgIYlrE09v08whVvu2at12hbP77ffew8f/4X3+rbH66R4t2//B332XjnpGNymZIPFcpxgH6DoVGJDrjOB29WmhtFH+zO05E8MXuOBHBF7vjRISm+uypTAajV3J/KtPCExs29Okkgp7BQTbu7h9QNoMbR9m4t0/70R09PWx8eM+ryuYXf/sdNqZKTtlsGd3Axp/74qeVzQ03XqO2xaXnVi0qG9TEtlDSNpDbLJ95WYwtH1H4hGbpMmObPJThW+qkFuv8sdVN5EYjOURWeAlB2/T18Wf2xc9+WNnM//WP1ban/u0FNv4/33hA2Xz2z77AxpkuneTSCOryjdvaO8r7sEit6lw1Jf3N7jgRwRe740QEX+yOExF8sTtORGiqQLdpxw585dFH+QREudxkVmdwJUSAjBRkACAudAkdLgMlGr22Z0yfSwge7bKaCoD/9J8/ysbvuOEqZROrGsJaqPBhzQo04dvICmqRuhp0tpZOvDKEG0tYW+1k5gQsUUipeA0cx7BR2qNxrsCNyJiPDGIZGdABTV/81AfUtup3nmDj555/Vtn84/f+gY3v/MOPK5uYyIxrJFTJuqs9w8NsHE/yoKNK+ezBS/5md5yI4IvdcSKCL3bHiQhN9dljySTaB2Swy+oVPKQLVmsgiaBquH/lIveZJ8dOKJviMg+iuedTdyqbm266jo1jtYqyAfS2IHx2CtZ+MojE8nX5d3Qjnndj3+uNBMegwTIrDRxbXpt1XFWtpYH51CzfXxhVdCDSlkHtx3/2rt9h49KPnlI2T/2IB+NsvepKZbPz37971Sk2onJ0ikSYVIZrSrWK9Zlawd/sjhMRfLE7TkTwxe44EcEXu+NEhKYKdASAGgod4KjKH1bwhdhUrerjLosqNDOnJpXNoAi2+L33vUvZJGVIhFHy1wqboCC2BWM/9fV7nkqOyg4zKryQFPqsA5mqmTCxrr8x2XBVpEBo6XNS0zSevf2M5H76mY128azM2999rbKZeXQ3G//iR/9P2bz9xuvZOG6UCK82cM/aOnlp75QIQivm82fd19/sjhMRfLE7TkTwxe44EWFVn52IvgXgDgCTIYS31rd1A/gugC0ADgP4aAhhdrVjBVg1VVb3U+Q3kvUNFROOW00GUQAYO3SEjQ/veVnZfOYOXhW2t1Mn5qAsEloMn5XICm4QPqHRJqiRIjD6njUQsGLcNRI+ewO1bOqGDfjj6kIacLYtVEyNcR3yWZf1cakik2X0M0sY7Z9q4llv7NIto7cNdrLxvmNHlc3UMR7ANbhDV8C1kmMkrV3cZ28T46U53pr6TBp5s38bgEwHug/A4yGE7QAer48dx1nHrLrYQwhPApgRm+8E8GD95wcB3AXHcdY15+uzD4QQTlfUPwlAV4CsQ0T3EtFuIto9PzV1nqdzHOdCuWCBLqyUszyr8xVCuD+EsCuEsKvTqBzrOE5zON+gmgkiGgohjBPREAAdndIgUuox5DCkxXdJ3FKtxLYiaQFm92O/4LsYGULvuXmXsLEqxcj9GrEBINsrGdchSwPbX6N0zqG1W0MhLo0UnGl0P2WzeoWZxuJ3DKMK30ZlI4BGBtoYATSoGqKduHHxqn6um7t56egDh/VfsL989Ek2vnPrJmVDoiJTMD4fmVYuELZt4CWyT43p6kunOd83+8MA7q7/fDcAXXDbcZx1xaqLnYi+A+BfAVxFRGNEdA+ALwF4PxEdAPB79bHjOOuYVf+MDyF84iy/et9FnovjOJeQpifCyKqvMh3AapyTbMDjlN5WJq73SQt/78adukXTlaL9MlVkGyUAJCrAygQXQPvnAGQR2BAzgj9UAotVFVZvUibnEdRimTRUOshMTGrARt0QI8hIaiZly9eWh7G0kNU91nKhYJyfP+uk8cy60vw6OtLaZvdjj7HxO//D7yib/m1b+LmNKadF4ousXGO1Kj+Nh8s6TkTwxe44EcEXu+NEBF/sjhMRmi7QyRPKPKOL1EjIDIZZOMVD/D/2++9RNmkhyIWabuOkMtqMYAwkjCsRgR2UsL5rGwiqURd7saJqGjgOANTkvI3rV/sZ16p6i+tnFoRoFgyBLhZLig06ew0UP9dwZbdEUW0rFvi2lGi3BADtWd7CrMVYVfmTPNjlyUd+omw+dO9n+HxSaWWTFNt6R3i/9oQxv9ePd9bfOI7zW4UvdseJCL7YHSci+GJ3nIjQVIEOWF0nsgr+ym2GtqKOOzO7qGwqi0tsvKlPlxhCRUZRGf2uSZaXMoQl60LEVyuRIaYkxNU1EPllq5qNlK5qoOCXmWEoS2kbpxdim/ncRXnnUDL648lyUpayJuZYM45TWebCa7mkhdeFOf2ZKQmBribFQADtGS6apa0syDI/9msvvqBMFiduZ+OOoUFlExMRcl19vJSE7NfO9j3rbxzH+a3CF7vjRARf7I4TEZrbnx26Eo30MBoIMznrsc9k8piu2JEVfdSzRjUbXb3G8Nmlk2pluMWMksdxcbvNbkurR8PoCiZGllcDWxoK4DFQUzSqvoRyaVUb1aappO91TQTVWH712NgEG08cn9bHKUnfX5lg8pSuhr4oquBs3LFD2bR1tLNxb5fO3cyKkjdzRw8qmxMv72fjTSPaZy+JYLGh0Y1snEzKvNI38De740QEX+yOExF8sTtORPDF7jgRoekCnRHGwli9i/ZZAm+E1jM3p8WWainHxqGiAytqIqsqDh2gQUqQM8Q4U1gTNlbkjerhbhxbin+NRPCYyMbmhmplZPRRkQeahPySsgkiiCVYAp0IkJmfmVc2Tz/9KzZ+7oV9ymZxgZ+rr69b2QwP8uCTVEb3R4+1taht1Rzvd37wtdeUzfU7d7Lx1dt0meh9x7iIeGRqQdnMjh1j44UJLTSm27kYODjKz5VMuUDnOJHHF7vjRARf7I4TEZpeqUamMaj228Z+ytuzOgCJAI1sZ6eyqYkEjmJBl4muprjfmjBKByvf20pWMaulrB61EmrSZ7f8aDEu6hLIqo2UDOgBgAQPaQpWIJCRMBIWuPZRXdKBLlXpsxsaxqSoHPSzx59WNvsO8L7mo1tGlM3tH76Nja/crnufo8gDdhbmtc88deqU2pYTSTXHJ/R+ZaH9DA/0KJvNQ7zk88lZrXMcO/AqG/d/TAfn5MTnoa+f909MeClpx3F8sTtORPDF7jgRwRe740SEpleqkRKVFOjsgJnVM8EqIvhjYkL3yC4sc1HEEugqWR6UkEpZ1VuE+BY3xDhrm0wyqxoZdSL4hCraJpS5aBTmctqmxK+NWnRZYrRzAYhadchTMDLRyjkuUi1N6+CP2Um+bXZOB8zs3X+IjZ//tc4EGxzkmV933P5+ZdPXz8WvwsSkslle4HMuGQFViZIuJT3QwwWw/FJe2RRy/No6egaUzeYhfpwDx7UYeOzVA2y8sKBFvPZuHjDU38ePm0y6QOc4kccXu+NEBF/sjhMRmuqzBwSUq9zflNVbLJ9deuxW3kc8zr+3isuGb5Xnvm2hoP22UoX72qmk1gdUy6qanlBlWft/S0vcbxw/fEzZxETgT8ZIzujs6GDj1ppO1qnOz7Gx1Woq0cPnaOoDcZ1YUSry+zZ1Qusjrx08zMb7jWs9ePQkG28a1pVZbn3PDWycP6wTUZ5/5lk2Pjmu51MSlXPSWX1dfRuH1Lb+NLcb7JS1loBjkzyoaOyw1oJmhY6QW9DBOZUif0b79+5XNjf/7s1s3NLWxcaxmPvsjhN5fLE7TkTwxe44EWHVxU5EG4noCSLaS0R7iOjz9e3dRPQYER2o/3/DpZ+u4zjnSyMCXQXAH4UQnieidgC/IqLHAPwhgMdDCF8iovsA3AfgT851oHK5ggkhVPQOD7Ox3f6Ji2RlWYIYWjSqGVVXqqLXesHIFitV+C0pG5VaTu4/zMZLizr4YWJqQm+b4IEUrx7S5a5rIqWtYFR4yaR5lZW3bu5TNlcP8+/eVELfj8Grt7FxMqZtclpnxKkj42x8Yuyksnnl4FFuY5RpHurhc9w+qCvMjO3lgSYJK2hEiLMt7TqAqCPJhc6c8cyWF7Volp/jmXktnXqOaXFvewb6lY3MynzqN68qm1KRC8i7f/64sunp5Rl12VZeuaaqSqG/wapv9hDCeAjh+frPiwD2ARgBcCeAB+tmDwK4a7VjOY6zdrwpn52ItgDYCeAZAAMhhNNf8ScB6BjBlX3uJaLdRLR7zgirdBynOTS82ImoDcAPAHwhhMD+3gkhBJyln0gI4f4Qwq4Qwq6uHp3U7zhOc2goqIZWegv/AMDfhxB+WN88QURDIYRxIhoCoLMPBNMTE/jfX/0a27b5Cl5VZPNb3qL26x8ZZeNsi07YIFFV06q6EhO+Xcnwb8pi2+5nXlQ2z/0rb7ebTGsfcWhY+9HdvdxH3bpji7KpieSYgyJZBADGhO//4qETyualV4+z8RUDunLPtgLXIzK9M8pmuaA1gyWR1LJ3r/Y/x6f4sdrb9DNrz/AAlcOHx5VNi0jOsQr3zIiWUOWK1lliokoQySq+AIYGtD/e2cGDVhJGy+aYCEZKp3QS1I5t/DN8w1u2KpunXuL3cd8v/1nZVJb5ud77QV6lp2JUFnp9nmf9TR1aqW/0AIB9IYS/OuNXDwO4u/7z3QB+vNqxHMdZOxp5s98C4NMA/o2ITr/m/gzAlwB8j4juAXAEwEcvzRQdx7kYrLrYQwhP4eyNVN93cafjOM6lwiPoHCciNDXrbTm3gJeffJRtm93HFfoXH9VteVItPHAgldaZYGkRXLA4o8WmpAhYiRtfdYvzPPhj78u63dDwjs1svGXrsLIZHdYZVN1dPFuttqyDehaneMZWuqxtNmT4xMendTDI9ALfb2xaB5HM5rn4d+PNHcpm61VXqm0xEWh04rgOqkmm+UcrbwSxTMn2RkZQz1yen6tF9EIHgJ4+fq9bs1owjYl/LIqTFvE6W7X4dsW2LWwcjFLN+Qn+WSsVdcZlWwcX/3Zes03ZvHjgCBvXgs5CnHhtDxs/8ndc1Jyb1hVwTuNvdseJCL7YHSci+GJ3nIjQ3Eo1tRqWCzwAYrnI/aRMMDIvAvc/q3n9HZUT7p+V6CA9uTQZQTWiKuv27ZuVTX8/9xGHhnSkcNWoQrr3n3l7o9yitpkX815c1K2VFnI8YSJnVIAtiMSLmOxpDaA9y+9jOqV95oEtWnuoiZZIO3derWz2vvQKG2eNFKfrNvPKNOmk9pmzIqim20gykbOuGoElpSJ/rsWythnZslFt6xHtn/PGvW4RGsFiUX+GC6Jy0kBvl7IZGeDbrAq0GRGcdGqSB1RVjOs6jb/ZHSci+GJ3nIjgi91xIoIvdseJCE0V6CrVCqYXeIljJLlwEzd6nXe180CKYFSqSSW4SFK22haJMtZzotwyAPQOinN19SqbAdE2aeaQzvr66c/+RW2ribZNXd06E20uz4WkU0YLoNkct4kbGX49olrLjTu1+DQ7yYNBEjGdCUZGf/p4hh+7b0iLZv0neKBNsksHQsWEGHpqQpebnirz5zg1prPn5NVnjDLRsnrM9uuuVTZtG3QKtuw8VpzXZaJlBl0mo4N64iIYh8pasGxr41mAtZoW2+ZmeXJpEEu4VtPP8DT+ZneciOCL3XEigi92x4kIvtgdJyI0VaCjeAKZdh4l1L+ZC0elvBZAZM9pS6CriQixSsWIxBNiT9GwWVjkx8mm9C06duQwG//Ls7p01SsndJWuPpH1duKoLifV2cVFu85eXY6/rZMLhO1pfT86RWZcR7uOTosTP9fw5lFlQ1YpAyGitnXpaLChYR5VmJfCLICh3hE23rhNR+vNTvIsQKs/eoe4Zz2DOqJxwxA/drJT31cy3n35eR6tuLSgIxpTSS7ItXTo+1Emcf+NPoOJBC9nlU3rZ7aY59efTsvec2YpSAD+ZnecyOCL3XEigi92x4kITfXZ4xRDW5oHRbx1By8dPT2tK8zEhI9YNrOaeGbcgtH+aUns9/JRXbq492rut7an9ffhyQm+3+Ss9kczWe1vdXRw3+6GjTqjrqeL++P5gtYwZsQ9mjLuWTHwRzswaASMlHhgR2uHDvIx+3EJkgkdRDI4KrSYgg5OKs7zrK7+bVcom4GtW/h0yjpYKi7KiMcyOvCmLGpQn5rRz6y6rDWcyjIPhErE9XNtzfLzlQy/uVTix86JzEUAILFfixGcM7fA96vGxRKWUUBn4G92x4kIvtgdJyL4YneciOCL3XEiQlMFulqtpnqZz07xelKyxA8AtIsss3hCZzVVKjzb5+hBI2hBlECemplXNgtzXGzpT2vRausmXk5p07DuEZY3MupScS4SWeWT5qd5j7ZTMzqIY1aINL3dugT0Le95BxsPbdIBKwWZPWd89wfovmXyHREMEa8qsrpiMX2cQoGLbRXSNokMz5arJbRAlxfZhGWjqXy5woWrZE2fK5M0MvNE1l/ByKaUpaqse6aS0YwyYRtEmezWFl0iPAYuxlZFn7ngAp3jOL7YHSci+GJ3nIjQVJ+9VCrh2HFejeSnj3MfpM3ovZ4UgQOZrG4R1SK2dRi+f0r4Xx98743KJp3jgR6Vgm6/1N3Okw+yLdpnLm/QcyzlRQnoOe1bVkU/9Ex/m7J569Wb2HjTNt3ru0NUZikYwTnVGtcQasa1ylZPAABRdcXSUMqi3HRuTgf+LM7x+1Fb1v5wSiROVQ2/OpHg9zqukkOAuNAMwpIOaqkuaA2ntMQ1JqNwD0jco1DT94xEUE86qZfecD/XfnIFXer86BgP6MoX+GcoWAJKHX+zO05E8MXuOBHBF7vjRARf7I4TEZrb6w2A1C4SSSHuGNlqqRQXV+JG8RTZf7ta1eJGazsXd0LQNv39PDuL8jqoJSF6jyeNajbZNl1eORbn2/prOuutJvqEBSP4IiEyBxNZLUjJ3WbHdeWcjMgWq7VoEQ9G7zDK8OCPeFaLqllRrWXBCGCan+NVVwozWsRrjYtS44YYmEgJ0c4QGiEDdqzgE2NTXHw+U0G/H4tCjLSK+8iDV42Sz9k0P9fbrtbC68zMLBs/9+u95zoNw9/sjhMRfLE7TkRYdbETUYaIniWiXxPRHiL6i/r2rUT0DBEdJKLvEpH++8pxnHVDIz57EcCtIYQcESUBPEVE/wjgiwC+EkJ4iIi+AeAeAH9zziMFoCYqw6aF37jVqHA6IgJEXn75oLJZllU34zr4QvpSR8Z0pZorr+UBK60bdCJMOiaSPJL6OzPeYgR/iMAfMvQJiFZO8n4BQFkEeszP6aSbxUnRJqhsJIeI6im1Tp3Qg4r2LWXQSEzqLgCy7TzQqKtXV6qZn+ZJUAtz2q9vjfPzx+L6XidbuT5AKa1hxOJijjH90bdc7ViMV6aJp/V+8SDurRFUUxPBLtWK1kJioixQZ1e7svnkR25j49w8v2fjJ/U9fOP4qxBWOB1ulKz/FwDcCuD79e0PArhrtWM5jrN2NOSzE1GciF4EMAngMQCvApgLb8jZYwBGzra/4zhrT0OLPYRQDSFcD2AUwI0Arm70BER0LxHtJqLd58q1dRzn0vKm1PgQwhyAJwDcBKCLiE47MKMAjp9ln/tDCLtCCLtMH9VxnKawqkBHRH0AyiGEOSLKAng/gC9jZdF/BMBDAO4G8OPVTxdUm6aSKNV71CjvPDEuMtGMQA+ZRVQp64CZIPpoHx4/qWwWN3ORqqXV6LUtBLmYPhXmp3SAyJKs3pLSx0aCC0KhaAS1iOy5RFkHkbQm+ByrRmWWIMWnlA6OsUpJB9GCqVbQ2WpBlHyuVPRNahEViJaKOoBpqcSfWSroay0IwTLTroXGZFaIXUb56xrp5SCDk6w/TuUrzMo8q9ZENR3jMxxq/Jkl4vqZDfTxa/v0x7hg9+v95jt35Xhn/c0bDAF4kIjiWPlL4HshhEeIaC+Ah4joLwG8AOCBBo7lOM4asepiDyH8BsBOY/shrPjvjuNcBngEneNEhOYmwoSVCrNiKxtVqzqIIy/8v0RMf0dVhONcMtoEVURFkQkjGGVOVL/tTWlRsSaqniSNII6uVu3/thL3E2uGj5wQSSVJI/iiOs+DUYozE8pm8RRvBx1Pax81LXzmZXHtAJBb1ME4AdzXr8hEEABLwq/fs08HQs3O8+qpXUZb6VnRpmnXdTp5aP4kv9Zlo61zex+vrhtP64CVIANvANSER14yEpOK4jNbNj7DUrMolbT2IM+fTmiffUEE0WQzPFArZqyN13931t84jvNbhS92x4kIvtgdJyL4YneciNBUgQ6AqqTR282zyrq7tXBSE1VnZB9rAMimubiTSlitjLhAVyjr4IeJBS4aXdFjVIER+osVRBE3AjTiohIJGQIMKlwQq+Z0C6DKIhdp5iZ0cNBynottgz0662xRlE4+9NJryub4pC653DfAjxVPaGFtRmSwPWMc+5XDPADkrZv7lM2OUX6uG9/9NmXTs4nf1+kTY3o+k/weZdq08Ghly1VFhZuiEVSzKAS5guyZDt1+ygqqSYsS2HGjbvUzz77Ixj95/Gk2PjnBA9DOxN/sjhMRfLE7TkTwxe44EaHpPrtMc02KpJJMRvuxFeFbJ41qJZmUSCAxqndWZYUV4zgnF3gyRgUD+jgizibEjGw+Mpy7igikqOjAn1pJth/WlUcKi7zC6NysTrpp6+5h4+yGHmUzvchbcT3z3EvKZmpBB8y0HeHJSp1duipPLs990nmjhfW7ruYBMjdds0XZDA1uYON40PdaVpfNipZRADAxzgNvcsvaZ061GnqR8L8LRnVZ6bPXWvRxisJnLxmJWh0pHiBTNZKHFvK8AvCrYzygqmgEk53G3+yOExF8sTtORPDF7jgRwRe740SEpgt0slLN/DwP2ujs1H3Na1IAMaqnkBDErLZJsipW3BDolioi8MboT55K8AMVq1oUsTQ7CMHFmmNNVKYpLmmBbmmBi135ZR0gMtjLA1QSHbp6y/AW/vg/fIe+H6UlfezFRZ5VVjREs+OiUs8t1+1QNts3DrJx3AiWiongqNyMDvJJplavylMVVWByRluvpJGtBlEmuyTbSAEoiD73MaMKTlFobVYb9RjxOeaXdTsu+YRk+zQiz3pznMjji91xIoIvdseJCM1PhBEUCtIn1H4TiYQAyy+pGEE0koTYz3CbsFzi/vdiUfusceG3VatGNZeM1h4S0t8zfPaKaDe8XNDVY+ZE4E8w2i+1iiCaYPjVcdECaXBQB96Ucrrqy8gIb8eVNKrg3CCq+VSNpKPCEvdJS4Y+khfVZSsFHWgSi6/errsS48+jVNHXVTAq9WR4MR+QURE4I7YFI8GpKnSVREwnD8knVDIqC1eErhA3KtCeDX+zO05E8MXuOBHBF7vjRARf7I4TEdZcoCuL7J9s1mjBI3qUW8EwcVFC16qomxD7JYzecyPDvDJKxQj0yAvhpFQzylYbARFtGVGJRE8RlRI/dm5ZlxyeE6JZS1uHspHtl6p5HYxSFeKj1aIpltRCkixLHcsYJbHjfL+icR1xkT4YK1uZivx+LJW0GFoSGWzVqha2ylIgzOo5B5mVCIBEVmZLh87wQ4ZvKxklqSFKcqcNUVP2vS8bgqUstU5xfg/P1U7R3+yOExF8sTtORPDF7jgRwRe740SENRfoKhUuOGzYoMv5yt5uSSNCqUcKJ0YZ3mUhAMLPGroAAAweSURBVBVyWpDp7+ViVzypz5UT/bYSpIWlRUOQymd4hFan0Q+uJCKt5hd0VNeMyBTMtHUqmyVRBqpc0IJQTMRskSEZxluMSMBWfr54tk3ZSKUolTIyA7NcEEwYAh2JCMvKgs5WWxY942QUJADURMSaFGsBIJbU6lbbBl5iqrVTX2tNCHKhopeV7Ove2qo/5xUhqloRhUUhDstSa1b/+NP4m91xIoIvdseJCL7YHScirLnPviyCSCaNyiyZLPe3WuI60ENmQ0ktAAAWhY9eWtJBJC+8xPuIj7zzWmWTL3DfKmP4elZnp3yRB9rIABoAKC7xOU5OzCqbxSV+/pTRtmh5WQTVVPT3erad+6PJjNHqivS9zpf59cZjhq8tfPaFKf1cpyf5tS0XtK8t/e+ikdEmfW0jwQ41keMYDE1HahgAkMpyrSOZMVo7iUo10FMEiSzAbFZrIadm+T2qGVVxqiK7U5ZmPxf+ZneciOCL3XEigi92x4kIDS92IooT0QtE9Eh9vJWIniGig0T0XSIyov8dx1kvvBmB7vMA9gE4HXXyZQBfCSE8RETfAHAPgL95sxMoCmHt1LzOzkoX+TQThvolSz4ljHI9JASYYPRje+EQ73+WNcSeGzbyskx5VVoLaDG++mR5rfmcvtalOZ7RNj6le6QND29k40y7znqTolGQIhKAwgIXA6ePTCubmRkdxDK/yIXGqlFeKy5qaefmdXDQyWl+7Om8vo850fuuRvqB9HTzQJcN3TozbbCPBzB1tRmZk0ZwVFmWgUro+1guyTkZvQgzq78LyyKoJpYyjpPmgmlMfs4vNOuNiEYB3A7gm/UxAbgVwPfrJg8CuKuRYzmOszY0+mf8VwH8Md6o0dgDYC6EcPprdwzAiLUjEd1LRLuJaPcFzdRxnAti1cVORHcAmAwh/Op8ThBCuD+EsCuEsOt89ncc5+LQiM9+C4APEdFtADJY8dm/BqCLiBL1t/sogOPnM4GqqEKTSekptbVxf6c1q5M6EiJoQfo2AFAsikSYvA7iKIkghT0nTiqbqwZ5NZu00cvHSmJIZfh3a6rNqMoDHmwxgH5lMzDAtxWNxA9ZOnp+ekHZ7Nl/hI0PHplQNlY9HRlUdN31W5XN1Dhv/7SU03NMd3E/+thJrU/khB/b0qEDfw68yq+jc0IHrPSPcz/+2q19ymZTv5GcIoKzyOjrFVRRcq1hyOStXEFXMiqKKjyyRDUAJEViVkxWqjmH077qmz2E8KchhNEQwhYAHwfwTyGETwJ4AsBH6mZ3A/jxasdyHGftuJB/Z/8TAF8kooNY8eEfuDhTchznUvCmYuNDCD8H8PP6z4cA3Hjxp+Q4zqXAI+gcJyKsedabLBPd1qKntGmjCBoxAl2KBS6klMs6o0xmCLW0aDEjK4SUwrSuOHPg+CQbv33jBj0fo0dcNiUzn/S1trYLUSalg1EmFk+xcbymxchFkfX2wiuHlc2BsSk27h/UotUffORWte3YayfY+D9+4n3KZmmBBwwdOzypbHo2D7Hx17/+sLJ55Zf72ThpPPz5PH9GC0bfv6IIxqkd1jYdrUNqW0mU167VVi/vXDP66smG7IVl3WtO9nbLtGqhL5Pizzopgmq8lLTjOL7YHScq+GJ3nIiw5j57EEkUve3a/0yI0h+5vC4F0tvF/fqlJe2zy+opwQh+KAlX6tSS9r13H+BBHNdt0T571uiZXq1yP7pQMPzGTn79nT26Au3ELPe1p6f1HF87yYNo9gj/HAAWivw+tsS1w3dkTgfj/GQ396MPLOoAkXKRX+vel3XMVUkk50xO6mo2ZRHUkzL84Y29/P7HjWSZazdzPaK71eiPbmhB0h+X7coAXT3GqpJUFIFI+bzWYmpCU5LJRAAQE9ti53LS5b4NWzqOc1nji91xIoIvdseJCL7YHScirLlAVxXZYcvzWuxJprhwUatoJaVdVAJJGWKL3G16VleKmZ7mCt38os7Wmi9zQWz/8Rllc/MOHaCBGt+vWtbXWhBVbzJGhl9aBOckjB7qRRGslG7RbYuyMS5i/uaVcWVzauZptU1WAXr+6X3KpjXFn0e1qO/jnAj8GTJaK3WJ5zrS1a5sOrPcZuzEKWWzWbSx2m5kvS0XjR72Iqgml9PCmixdnctpgW52ju9XqxmtthIxMdY2FbFeZJWgcxWW9je740QEX+yOExF8sTtORFhzn112r5me0MEww/1dbDxn+LrPPssDPTpadDBKXx8/TiGnAyQW57jPXDJ6CSVEIMOTe44qmx1DOtBmuJtXQgkJ/V1bLi2LsT5/i/Bj29u0b3f91Zv4uWe1z/ziK3zeXQkdCHTLWzapbb2tohJMSfuoocwf7LIRjJIT+7WktPaQFO26M3H9kZ0Vba1PLetrTYr51Ip6zi0Zff4gfOSc0TK6KuJa5mb157NSFm3H0/rzKbpqmUE1EIk4KfEZOleQjb/ZHSci+GJ3nIjgi91xIoIvdseJCGsu0EliVS2SXDXC+0/sP65LHk9OcOGkYJRXHp/gWVWlkhaNEjKwwei9TiLz6qhRpvn5Q3qOPe2b2bjV6IceRAZVuajnKAW6qarOFutr5wJhb2uXsinNcmFr/yGdmTZoBHZsapVCo55jRd7brJEFKMTZihEsVSjz+zFvBbWItlFbRnT5bQr8uS4s6c9He9rohy7GMaMKTkVUz1kyqtB0dQ6wsRGrhbiYIxntyUicSwqY58qB8ze740QEX+yOExF8sTtORFh3PvuR47Nq2/N7D7HxzLIOWiDhuwTLexE+UNboq1wSVWmTSX2LKhV+nIKRdPPcq9pn37mF+5LJuA6siMW5ZlE2tIeEuNa2jJ5jRiTLVAra/3vXtTvYePyIrgA7M6X1iEHRoqstpn3dDnH+TMq41yJgZXJGaw8yYCaW1Ykw1910HRufPK4TekpVriHMLmudgUrWdXB9Ip7RD7tY4HOMG5+Zrg28ktLihG51lRABQ1ZMjST2Jl7X/mZ3nIjgi91xIoIvdseJCL7YHScikGyJdElPRjQF4AiAXgC6nMj65nKcM3B5ztvnfP5sDiHoMjxo8mJ//aREu0MIu5p+4gvgcpwzcHnO2+d8afA/4x0nIvhid5yIsFaL/f41Ou+FcDnOGbg85+1zvgSsic/uOE7z8T/jHSci+GJ3nIjQ9MVORB8goleI6CAR3dfs8zcCEX2LiCaJ6KUztnUT0WNEdKD+f10+dg0hoo1E9AQR7SWiPUT0+fr2dTtvIsoQ0bNE9Ov6nP+ivn0rET1T/4x8l4h0Fs0aQ0RxInqBiB6pj9f9nJu62IkoDuCvAXwQwDUAPkFE1zRzDg3ybQAfENvuA/B4CGE7gMfr4/VEBcAfhRCuAfBuAP+lfm/X87yLAG4NIbwdwPUAPkBE7wbwZQBfCSFcCWAWwD1rOMez8XkAZ/a9Wvdzbvab/UYAB0MIh0IIJQAPAbizyXNYlRDCkwBkA7c7ATxY//lBAHc1dVKrEEIYDyE8X/95ESsfxBGs43mHFU43WEvW/wsAbgXw/fr2dTVnACCiUQC3A/hmfUxY53MGmr/YRwAcO2M8Vt92OTAQQjidKH0SwMC5jNcSItoCYCeAZ7DO513/c/hFAJMAHgPwKoC5EMLphPP1+Bn5KoA/Bl4vCNeD9T9nF+jOh7Dy75Xr8t8siagNwA8AfCGEwCpPrMd5hxCqIYTrAYxi5S+/q9d4SueEiO4AMBlC+NVaz+XN0uxKNccBbDxjPFrfdjkwQURDIYRxIhrCyptoXUFESaws9L8PIfywvnndzxsAQghzRPQEgJsAdBFRov6mXG+fkVsAfIiIbgOQAdAB4GtY33MG0Pw3+3MAtteVyxSAjwN4uMlzOF8eBnB3/ee7Afx4DeeiqPuNDwDYF0L4qzN+tW7nTUR9RNRV/zkL4P1Y0RqeAPCRutm6mnMI4U9DCKMhhC1Y+fz+Uwjhk1jHc36dEEJT/wNwG4D9WPHN/muzz9/gHL8DYBxAGSv+1z1Y8cseB3AAwM8AdK/1PMWc34OVP9F/A+DF+n+3red5A3gbgBfqc34JwH+rb98G4FkABwH8XwDptZ7rWeb/XgCPXC5z9nBZx4kILtA5TkTwxe44EcEXu+NEBF/sjhMRfLE7TkTwxe44EcEXu+NEhP8PNFu9sRJjq90AAAAASUVORK5CYII=\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "#we can view some images and their labels\n",
        "import matplotlib.pyplot as plt\n",
        "idx = np.random.randint(low=0, high=len(trainset)-1)\n",
        "print('chosen index: ', idx)\n",
        "image, label = trainset[idx] # the image has format of h, w, c -> so it have to be reshaped\n",
        "plt.imshow(image.permute(1, 2, 0))\n",
        "plt.title(label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5BU0SeIctamL",
        "outputId": "1c10a434-ac57-4e27-b71e-5cf5e5a53b3f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total batches in trainloader:  386 , validloader:  29 , and testloader 3589\n"
          ]
        }
      ],
      "source": [
        "#now let's read the dataset using pytorch's dataloader\n",
        "trainloader = DataLoader(trainset, batch_size=batch_size, shuffle=True)\n",
        "validloader = DataLoader(validset, batch_size=batch_size)\n",
        "testloader = DataLoader(testset)\n",
        "print('total batches in trainloader: ', len(trainloader), ', validloader: ', len(validloader), ', and testloader', len(testloader))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HPjkKbNXsyhM",
        "outputId": "6f608c8a-6d45-4beb-e809-45cc4d501e7f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "shape of a batch of images: torch.Size([128, 3, 48, 48])\n",
            "shape of a batch of labels: torch.Size([128])\n"
          ]
        }
      ],
      "source": [
        "#checking the shapes of each batch\n",
        "for images, labels in trainloader:\n",
        "  break\n",
        "print(f'shape of a batch of images: {images.shape}')\n",
        "print(f'shape of a batch of labels: {labels.shape}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "gfjbdWSG1s4x"
      },
      "outputs": [],
      "source": [
        "from torchvision import models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mSG4M3c2wAiw",
        "outputId": "92784bbe-9c47-42f6-a222-d89f7649b3af"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sequential(\n",
              "  (0): ReLU(\n",
              "    inplace=True\n",
              "    (inplace): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "  )\n",
              "  (1): Dropout(p=0.2, inplace=False)\n",
              "  (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (3): ReLU(\n",
              "    inplace=True\n",
              "    (inplace): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "  )\n",
              "  (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (5): ReLU(\n",
              "    inplace=True\n",
              "    (inplace): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "  )\n",
              "  (6): Dropout(p=0.2, inplace=False)\n",
              "  (7): ReLU(\n",
              "    inplace=True\n",
              "    (inplace): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "  )\n",
              "  (8): Flatten(start_dim=1, end_dim=-1)\n",
              "  (9): ReLU(\n",
              "    inplace=True\n",
              "    (inplace): Linear(in_features=36864, out_features=432, bias=True)\n",
              "  )\n",
              "  (10): Linear(in_features=432, out_features=7, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "model = nn.Sequential(\n",
        "          nn.ReLU(nn.Conv2d(in_channels=3, out_channels=32, kernel_size=(3, 3), padding='same')),\n",
        "          nn.Dropout(0.2),\n",
        "          nn.MaxPool2d(2),\n",
        "          nn.ReLU(nn.Conv2d(in_channels=32, out_channels=64, kernel_size=(3, 3), padding='same')),\n",
        "          nn.MaxPool2d(2),\n",
        "          nn.ReLU(nn.Conv2d(in_channels=64, out_channels=128, kernel_size=(3, 3), padding='same')),\n",
        "          nn.Dropout(0.2),\n",
        "          nn.ReLU(nn.Conv2d(in_channels=128, out_channels=256, kernel_size=(3, 3), padding='same')),\n",
        "          nn.Flatten(),\n",
        "          nn.ReLU(nn.Linear(256*12*12, 432)),\n",
        "          nn.Linear(432,7)          \n",
        "        )\n",
        "model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "mpHoVI9VwEuP"
      },
      "outputs": [],
      "source": [
        "#accuracy of the model\n",
        "from tqdm import tqdm\n",
        "def multiclass_accuracy(y_pred,y_true):\n",
        "    top_p,top_class = y_pred.topk(1,dim = 1)\n",
        "    equals = top_class == y_true.view(*top_class.shape)\n",
        "    return torch.mean(equals.type(torch.FloatTensor))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "5gmlWz2fwy9Q"
      },
      "outputs": [],
      "source": [
        "#building the train and eval functions (training the model on the training and on the validation set)\n",
        "def train_model(model, dataloader, optimizer, current_epoch):\n",
        "\n",
        "  model.train()\n",
        "  total_loss = 0.0\n",
        "  total_acc = 0.0\n",
        "  tk = tqdm(dataloader, desc='EPOCH' + '[TRAIN]' + str(current_epoch + 1) + \"/\" + str(epochs))\n",
        "\n",
        "  for t, data in enumerate(tk):\n",
        "    images, labels = data\n",
        "    images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    logits = model(images)\n",
        "    loss = nn.CrossEntropyLoss()(logits,  labels)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    total_loss += loss.item()\n",
        "    total_acc += multiclass_accuracy(logits, labels)\n",
        "    tk.set_postfix({'loss': float(total_loss/(t+1)),'acc': float(total_acc/(t+1))})\n",
        "  return total_loss/len(dataloader), total_acc / len(dataloader)\n",
        "\n",
        "def eval_model(model, dataloader, current_epoch):\n",
        "\n",
        "  model.eval()\n",
        "  total_loss = 0.0\n",
        "  total_acc = 0.0\n",
        "  tk = tqdm(dataloader, desc='EPOCH' + '[VALID]' + str(current_epoch + 1) + \"/\" + str(epochs))\n",
        "\n",
        "  for t, data in enumerate(tk):\n",
        "    images, labels = data\n",
        "    images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "    logits = model(images)\n",
        "    loss = nn.CrossEntropyLoss()(logits,  labels)\n",
        "\n",
        "    total_loss += loss.item()\n",
        "    total_acc += multiclass_accuracy(logits, labels)\n",
        "    tk.set_postfix({'loss': float(total_loss/(t+1)),'acc': float(total_acc/(t+1))})\n",
        "  return total_loss/len(dataloader), total_acc / len(dataloader)\n",
        "\n",
        "def test_model(model, dataloader, current_epoch=1):\n",
        "\n",
        "  model.eval()\n",
        "  total_loss = 0.0\n",
        "  total_acc = 0.0\n",
        "  tk = tqdm(dataloader, desc='EPOCH' + '[TEST]' + str(current_epoch + 1) + \"/\" + str(epochs))\n",
        "\n",
        "  for t, data in enumerate(tk):\n",
        "    images, labels = data\n",
        "    images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "    logits = model(images)\n",
        "    loss = nn.CrossEntropyLoss()(logits,  labels)\n",
        "\n",
        "    total_loss += loss.item()\n",
        "    total_acc += multiclass_accuracy(logits, labels)\n",
        "    tk.set_postfix({'loss': float(total_loss/(t+1)),'acc': float(total_acc/(t+1))})\n",
        "  return total_loss/len(dataloader), total_acc / len(dataloader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "rzj7fwZoxLN_"
      },
      "outputs": [],
      "source": [
        "#now let's train the model\n",
        "from torch import optim\n",
        "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "# optimizer = optim.SGD(model.parameters(), lr=lr, momentum=0.5, weight_decay=1e-2, nesterov=True) # gives much better accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "AGamEDaZyPxv",
        "outputId": "44e0ad48-c29b-456f-dfae-6301be1dfada"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "EPOCH[TRAIN]1/50: 100%|██████████| 386/386 [2:10:45<00:00, 20.32s/it, loss=1.93, acc=0.214]\n",
            "EPOCH[VALID]1/50: 100%|██████████| 29/29 [09:37<00:00, 19.93s/it, loss=1.87, acc=0.237]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SAVED BEST WEIGHTS\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "EPOCH[TRAIN]2/50: 100%|██████████| 386/386 [10:42<00:00,  1.67s/it, loss=1.92, acc=0.22]\n",
            "EPOCH[VALID]2/50: 100%|██████████| 29/29 [00:05<00:00,  5.75it/s, loss=1.87, acc=0.237]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SAVED BEST WEIGHTS\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "EPOCH[TRAIN]3/50: 100%|██████████| 386/386 [10:39<00:00,  1.66s/it, loss=1.91, acc=0.222]\n",
            "EPOCH[VALID]3/50: 100%|██████████| 29/29 [00:05<00:00,  5.79it/s, loss=1.87, acc=0.237]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SAVED BEST WEIGHTS\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "EPOCH[TRAIN]4/50:  32%|███▏      | 123/386 [03:21<06:42,  1.53s/it, loss=1.9, acc=0.223]"
          ]
        }
      ],
      "source": [
        "best_valid_loss = np.Inf\n",
        "train_losses = []\n",
        "validation_losses = []\n",
        "for i in range(epochs):\n",
        "  train_loss, train_acc = train_model(model, trainloader, optimizer, i)\n",
        "  valid_loss, valid_acc = eval_model(model, validloader, i)\n",
        "  train_losses.append(train_loss)\n",
        "  validation_losses.append(valid_loss)\n",
        "\n",
        "  if valid_loss < best_valid_loss:\n",
        "    torch.save(model.state_dict(), 'Baseline.h5')\n",
        "    print('SAVED BEST WEIGHTS')\n",
        "    best_valid_loss = valid_loss\n",
        "print()\n",
        "print()\n",
        "print('accuracy on the training set: ', float(train_acc))\n",
        "print('accuracy on the validation set: ', float(valid_acc))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "2SWd3tteW85B"
      },
      "outputs": [],
      "source": [
        "def plot_the_loss_curve(epochs, training_losses, validation_losses):\n",
        "  \"\"\"Plot a curve of loss vs. epoch.\"\"\"\n",
        "  epochs = list(range(1, epochs + 1))\n",
        "  plt.figure(figsize=(10, 5))\n",
        "  plt.xlabel(\"Epoch\")\n",
        "  plt.ylabel(\"Cross Entropy losses\")\n",
        "\n",
        "  plt.plot(epochs[1:], training_losses[1:], label=\"Training Loss\")\n",
        "  plt.plot(epochs[1:], validation_losses[1:], label=\"Validation Loss\")\n",
        "  plt.legend()\n",
        "  \n",
        "  # We're not going to plot the first epoch, since the loss on the first epoch\n",
        "  # is often substantially greater than the loss for other epochs.\n",
        "  merged_losses = training_losses[1:] + validation_losses[1:]\n",
        "  highest_loss = max(merged_losses)\n",
        "  lowest_loss = min(merged_losses)\n",
        "  delta = highest_loss - lowest_loss\n",
        "  print(delta)\n",
        "\n",
        "  top_of_y_axis = highest_loss + (delta * 0.05)\n",
        "  bottom_of_y_axis = lowest_loss - (delta * 0.05)\n",
        "  plt.title('loss curve') \n",
        "  plt.ylim([bottom_of_y_axis, top_of_y_axis])\n",
        "  plt.show()  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "iiwO-lyAXB4T"
      },
      "outputs": [],
      "source": [
        "plot_the_loss_curve(epochs, train_losses, validation_losses)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "jyfdP1m3g9J6"
      },
      "outputs": [],
      "source": [
        "test_loss, test_acc = test_model(model, testloader)\n",
        "print()\n",
        "print('accuracy on the test set: ', float(test_acc))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Baseline.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}