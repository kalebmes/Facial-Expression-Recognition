{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "VGG19.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kalebmes/Facial-Expression-Recognition/blob/main/Models/VGG19.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#mount your drive first - you can do it once\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "_hbOvpcyD-7H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "394d78ef-c0a7-4ca0-fbf7-ea2914a04704"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#importing necessary modules\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from PIL import Image\n",
        "import os\n",
        "import torchvision.datasets as dset\n",
        "import torchvision.transforms as T"
      ],
      "metadata": {
        "id": "1O_7o8yiL7fZ"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#hyperparameters start form \n",
        "lr = 1e-3\n",
        "batch_size = 128\n",
        "epochs = 50\n",
        "\n",
        "#device\n",
        "device = 'cpu'\n",
        "if torch.cuda.is_available():\n",
        "  device = 'cuda'\n",
        "  print('GPU available')\n",
        "else:\n",
        "  print('training is done on CPU')"
      ],
      "metadata": {
        "id": "1AtbkaA7Ozsy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "020386d3-d7c3-4514-aea0-8e21d909e8f5"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training is done on CPU\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#now let's load the dataset into the 'dataloader' package of pytorch\n",
        "from torchvision.datasets import ImageFolder\n",
        "import torchvision.transforms as T"
      ],
      "metadata": {
        "id": "mDauIl3KPaE4"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#first step is creating an augmentation cell using transforms of pytorch\n",
        "train_augs = T.Compose([T.RandomHorizontalFlip(p=0.5), \n",
        "                        T.RandomRotation(degrees=(-10, +10)),\n",
        "                        T.RandomAffine(degrees=(-10, +10), translate=(0.1, 0.2)),\n",
        "                        T.Resize((48, 48)),\n",
        "                        T.ToTensor()])\n",
        "\n",
        "valid_augs = T.Compose([T.ToTensor()])\n",
        "\n",
        "test_augs = T.Compose([T.ToTensor()])"
      ],
      "metadata": {
        "id": "3Mn5MAN8SsUR"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_path = '/content/drive/MyDrive/datasets'\n",
        "train_path = os.path.join(data_path, 'train')\n",
        "validation_path = os.path.join(data_path, 'validation')\n",
        "test_path = os.path.join(data_path, 'test')"
      ],
      "metadata": {
        "id": "xJKiovhRb1Yz"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainset = ImageFolder(train_path, transform=train_augs)\n",
        "validset = ImageFolder(validation_path, transform=valid_augs)\n",
        "testset = ImageFolder(test_path, transform=test_augs)\n",
        "print(f\"Total no. of examples in trainset : {len(trainset)}\")\n",
        "print(f\"Total no. of examples in validset : {len(validset)}\")\n",
        "print(f\"Total no. of examples in testset : {len(testset)}\")"
      ],
      "metadata": {
        "id": "-iRhgKwIS3jX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8c9daec0-cb9b-4eae-c7de-1ba350f34d73"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total no. of examples in trainset : 17148\n",
            "Total no. of examples in validset : 3069\n",
            "Total no. of examples in testset : 2970\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(trainset.class_to_idx)"
      ],
      "metadata": {
        "id": "SrM66qzviRg6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "30e6d698-5592-4a40-d667-987fd9e2b027"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'anger': 0, 'disgust': 1, 'fear': 2, 'happy': 3, 'neutral': 4, 'sad': 5, 'surprise': 6}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#we can view some images and their labels\n",
        "import matplotlib.pyplot as plt\n",
        "idx = np.random.randint(low=0, high=len(trainset)-1)\n",
        "print('chosen index: ', idx)\n",
        "image, label = trainset[idx] # the image has format of h, w, c -> so it have to be reshaped\n",
        "plt.imshow(image.permute(1, 2, 0))\n",
        "plt.title(label)"
      ],
      "metadata": {
        "id": "4KPvBCwgiWqI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#now let's read the dataset using pytorch's dataloader\n",
        "trainloader = DataLoader(trainset, batch_size=batch_size, shuffle=True)\n",
        "validloader = DataLoader(validset, batch_size=batch_size)\n",
        "testloader = DataLoader(testset)\n",
        "print('total batches in trainloader: ', len(trainloader), ', validloader: ', len(validloader), ', and testloader', len(testloader))"
      ],
      "metadata": {
        "id": "5BU0SeIctamL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#checking the shapes of each batch\n",
        "for images, labels in trainloader:\n",
        "  break\n",
        "print(f'shape of a batch of images: {images.shape}')\n",
        "print(f'shape of a batch of labels: {labels.shape}')"
      ],
      "metadata": {
        "id": "HPjkKbNXsyhM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import models"
      ],
      "metadata": {
        "id": "gfjbdWSG1s4x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = models.vgg19(pretrained=True)\n",
        "model.classifier[-1] = nn.Sequential(nn.Linear(in_features=4096, out_features=7))\n",
        "model.to(device)"
      ],
      "metadata": {
        "id": "mSG4M3c2wAiw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#accuracy of the model\n",
        "from tqdm import tqdm\n",
        "def multiclass_accuracy(y_pred,y_true):\n",
        "    top_p,top_class = y_pred.topk(1,dim = 1)\n",
        "    equals = top_class == y_true.view(*top_class.shape)\n",
        "    return torch.mean(equals.type(torch.FloatTensor))"
      ],
      "metadata": {
        "id": "mpHoVI9VwEuP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#building the train and eval functions (training the model on the training and on the validation set)\n",
        "def train_model(model, dataloader, optimizer, current_epoch):\n",
        "\n",
        "  model.train()\n",
        "  total_loss = 0.0\n",
        "  total_acc = 0.0\n",
        "  tk = tqdm(dataloader, desc='EPOCH' + '[TRAIN]' + str(current_epoch + 1) + \"/\" + str(epochs))\n",
        "\n",
        "  for t, data in enumerate(tk):\n",
        "    images, labels = data\n",
        "    images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    logits = model(images)\n",
        "    loss = nn.CrossEntropyLoss()(logits,  labels)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    total_loss += loss.item()\n",
        "    total_acc += multiclass_accuracy(logits, labels)\n",
        "    tk.set_postfix({'loss': float(total_loss/(t+1)),'acc': float(total_acc/(t+1))})\n",
        "  return total_loss/len(dataloader), total_acc / len(dataloader)\n",
        "\n",
        "def eval_model(model, dataloader, current_epoch):\n",
        "\n",
        "  model.eval()\n",
        "  total_loss = 0.0\n",
        "  total_acc = 0.0\n",
        "  tk = tqdm(dataloader, desc='EPOCH' + '[VALID]' + str(current_epoch + 1) + \"/\" + str(epochs))\n",
        "\n",
        "  for t, data in enumerate(tk):\n",
        "    images, labels = data\n",
        "    images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "    logits = model(images)\n",
        "    loss = nn.CrossEntropyLoss()(logits,  labels)\n",
        "\n",
        "    total_loss += loss.item()\n",
        "    total_acc += multiclass_accuracy(logits, labels)\n",
        "    tk.set_postfix({'loss': float(total_loss/(t+1)),'acc': float(total_acc/(t+1))})\n",
        "  return total_loss/len(dataloader), total_acc / len(dataloader)\n",
        "\n",
        "def test_model(model, dataloader, current_epoch=1):\n",
        "\n",
        "  model.eval()\n",
        "  total_loss = 0.0\n",
        "  total_acc = 0.0\n",
        "  tk = tqdm(dataloader, desc='EPOCH' + '[TEST]' + str(current_epoch + 1) + \"/\" + str(epochs))\n",
        "\n",
        "  for t, data in enumerate(tk):\n",
        "    images, labels = data\n",
        "    images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "    logits = model(images)\n",
        "    loss = nn.CrossEntropyLoss()(logits,  labels)\n",
        "\n",
        "    total_loss += loss.item()\n",
        "    total_acc += multiclass_accuracy(logits, labels)\n",
        "    tk.set_postfix({'loss': float(total_loss/(t+1)),'acc': float(total_acc/(t+1))})\n",
        "  return total_loss/len(dataloader), total_acc / len(dataloader)"
      ],
      "metadata": {
        "id": "5gmlWz2fwy9Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#now let's train the model\n",
        "from torch import optim\n",
        "# optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "optimizer = optim.SGD(model.parameters(), lr=lr, momentum=0.5, weight_decay=1e-2, nesterov=True) # gives much better accuracy"
      ],
      "metadata": {
        "id": "rzj7fwZoxLN_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_valid_loss = np.Inf\n",
        "train_losses = []\n",
        "validation_losses = []\n",
        "for i in range(epochs):\n",
        "  train_loss, train_acc = train_model(model, trainloader, optimizer, i)\n",
        "  valid_loss, valid_acc = eval_model(model, validloader, i)\n",
        "  train_losses.append(train_loss)\n",
        "  validation_losses.append(valid_loss)\n",
        "\n",
        "  if valid_loss < best_valid_loss:\n",
        "    torch.save(model.state_dict(), os.path.join(data_path, 'VGG19-SGD.h5'))\n",
        "    print('SAVED BEST WEIGHTS')\n",
        "    best_valid_loss = valid_loss\n",
        "print()\n",
        "print()\n",
        "print('accuracy on the training set: ', float(train_acc))\n",
        "print('accuracy on the validation set: ', float(valid_acc))"
      ],
      "metadata": {
        "id": "AGamEDaZyPxv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_the_loss_curve(epochs, training_losses, validation_losses):\n",
        "  \"\"\"Plot a curve of loss vs. epoch.\"\"\"\n",
        "  epochs = list(range(1, epochs + 1))\n",
        "  plt.figure(figsize=(10, 5))\n",
        "  plt.xlabel(\"Epoch\")\n",
        "  plt.ylabel(\"Cross Entropy losses\")\n",
        "\n",
        "  plt.plot(epochs[1:], training_losses[1:], label=\"Training Loss\")\n",
        "  plt.plot(epochs[1:], validation_losses[1:], label=\"Validation Loss\")\n",
        "  plt.legend()\n",
        "  \n",
        "  # We're not going to plot the first epoch, since the loss on the first epoch\n",
        "  # is often substantially greater than the loss for other epochs.\n",
        "  merged_losses = training_losses[1:] + validation_losses[1:]\n",
        "  highest_loss = max(merged_losses)\n",
        "  lowest_loss = min(merged_losses)\n",
        "  delta = highest_loss - lowest_loss\n",
        "  print(delta)\n",
        "\n",
        "  top_of_y_axis = highest_loss + (delta * 0.05)\n",
        "  bottom_of_y_axis = lowest_loss - (delta * 0.05)\n",
        "  plt.title('loss curve') \n",
        "  plt.ylim([bottom_of_y_axis, top_of_y_axis])\n",
        "  plt.show()  "
      ],
      "metadata": {
        "id": "2SWd3tteW85B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_the_loss_curve(epochs, train_losses, validation_losses)"
      ],
      "metadata": {
        "id": "iiwO-lyAXB4T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_acc = test_model(model, testloader)\n",
        "print()\n",
        "print('accuracy on the test set: ', float(test_acc))"
      ],
      "metadata": {
        "id": "jyfdP1m3g9J6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}