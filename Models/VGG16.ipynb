{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "VGG16.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kalebmes/Facial-Expression-Recognition/blob/main/Models/VGG16.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#mount your drive first - you can do it once\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "_hbOvpcyD-7H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "40c5427a-7a23-4c4c-97d1-e9b62a1ee9c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#importing necessary modules\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from PIL import Image\n",
        "import os\n",
        "import torchvision.datasets as dset\n",
        "import torchvision.transforms as T"
      ],
      "metadata": {
        "id": "1O_7o8yiL7fZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#hyperparameters start form \n",
        "lr = 1e-3\n",
        "batch_size = 128\n",
        "epochs = 50\n",
        "\n",
        "#device\n",
        "device = 'cpu'\n",
        "if torch.cuda.is_available():\n",
        "  device = 'cuda'\n",
        "  print('GPU available')\n",
        "else:\n",
        "  print('training is done on CPU')"
      ],
      "metadata": {
        "id": "1AtbkaA7Ozsy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6b944670-0838-4245-a5ae-370d8b884753"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU available\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#now let's load the dataset into the 'dataloader' package of pytorch\n",
        "from torchvision.datasets import ImageFolder\n",
        "import torchvision.transforms as T"
      ],
      "metadata": {
        "id": "mDauIl3KPaE4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#first step is creating an augmentation cell using transforms of pytorch\n",
        "train_augs = T.Compose([T.RandomHorizontalFlip(p=0.5), \n",
        "                        T.RandomRotation(degrees=(-10, +10)),\n",
        "                        T.RandomAffine(degrees=(-10, +10), translate=(0.1, 0.2)),\n",
        "                        T.Resize((48, 48)),\n",
        "                        T.ToTensor()])\n",
        "\n",
        "valid_augs = T.Compose([T.ToTensor()])\n",
        "\n",
        "test_augs = T.Compose([T.ToTensor()])"
      ],
      "metadata": {
        "id": "3Mn5MAN8SsUR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_path = '/content/drive/MyDrive/datasets'\n",
        "train_path = os.path.join(data_path, 'train')\n",
        "validation_path = os.path.join(data_path, 'validation')\n",
        "test_path = os.path.join(data_path, 'test')"
      ],
      "metadata": {
        "id": "xJKiovhRb1Yz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainset = ImageFolder(train_path, transform=train_augs)\n",
        "validset = ImageFolder(validation_path, transform=valid_augs)\n",
        "testset = ImageFolder(test_path, transform=test_augs)\n",
        "print(f\"Total no. of examples in trainset : {len(trainset)}\")\n",
        "print(f\"Total no. of examples in validset : {len(validset)}\")\n",
        "print(f\"Total no. of examples in testset : {len(testset)}\")"
      ],
      "metadata": {
        "id": "-iRhgKwIS3jX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "43137591-19b7-4399-8632-6c03efb5efc2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total no. of examples in trainset : 49297\n",
            "Total no. of examples in validset : 3599\n",
            "Total no. of examples in testset : 3589\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(trainset.class_to_idx)"
      ],
      "metadata": {
        "id": "SrM66qzviRg6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e1565b73-e6cc-4e80-cc1f-76e304ff12a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'anger': 0, 'disgust': 1, 'fear': 2, 'happy': 3, 'neutral': 4, 'sad': 5, 'surprise': 6}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#we can view some images and their labels\n",
        "import matplotlib.pyplot as plt\n",
        "idx = np.random.randint(low=0, high=len(trainset)-1)\n",
        "print('chosen index: ', idx)\n",
        "image, label = trainset[idx] # the image has format of h, w, c -> so it have to be reshaped\n",
        "plt.imshow(image.permute(1, 2, 0))\n",
        "plt.title(label)"
      ],
      "metadata": {
        "id": "4KPvBCwgiWqI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316
        },
        "outputId": "cd041982-ded1-48a9-9675-e7b04c92d275"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "chosen index:  26307\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, '3')"
            ]
          },
          "metadata": {},
          "execution_count": 31
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#now let's read the dataset using pytorch's dataloader\n",
        "trainloader = DataLoader(trainset, batch_size=batch_size, shuffle=True)\n",
        "validloader = DataLoader(validset, batch_size=batch_size)\n",
        "testloader = DataLoader(testset)\n",
        "print('total batches in trainloader: ', len(trainloader), ', validloader: ', len(validloader), ', and testloader', len(testloader))"
      ],
      "metadata": {
        "id": "5BU0SeIctamL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "61bcd379-bdbf-4a75-baec-1f79c2000fc3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total batches in trainloader:  386 , validloader:  29 , and testloader 3589\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#checking the shapes of each batch\n",
        "for images, labels in trainloader:\n",
        "  break\n",
        "print(f'shape of a batch of images: {images.shape}')\n",
        "print(f'shape of a batch of labels: {labels.shape}')"
      ],
      "metadata": {
        "id": "HPjkKbNXsyhM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "781c96e4-e515-4c75-ff06-7545dc2367e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "shape of a batch of images: torch.Size([128, 3, 48, 48])\n",
            "shape of a batch of labels: torch.Size([128])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import models"
      ],
      "metadata": {
        "id": "gfjbdWSG1s4x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = models.vgg16(pretrained=True)\n",
        "model.classifier[-1] = nn.Sequential(nn.Linear(in_features=4096, out_features=7))\n",
        "model.to(device)"
      ],
      "metadata": {
        "id": "mSG4M3c2wAiw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f6289eea-ec2a-4bce-95d2-2dc1c7cca478"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "VGG(\n",
              "  (features): Sequential(\n",
              "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (3): ReLU(inplace=True)\n",
              "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (6): ReLU(inplace=True)\n",
              "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (8): ReLU(inplace=True)\n",
              "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (11): ReLU(inplace=True)\n",
              "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (13): ReLU(inplace=True)\n",
              "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (15): ReLU(inplace=True)\n",
              "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (18): ReLU(inplace=True)\n",
              "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (20): ReLU(inplace=True)\n",
              "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (22): ReLU(inplace=True)\n",
              "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (25): ReLU(inplace=True)\n",
              "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (27): ReLU(inplace=True)\n",
              "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (29): ReLU(inplace=True)\n",
              "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
              "  (classifier): Sequential(\n",
              "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): Dropout(p=0.5, inplace=False)\n",
              "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
              "    (4): ReLU(inplace=True)\n",
              "    (5): Dropout(p=0.5, inplace=False)\n",
              "    (6): Sequential(\n",
              "      (0): Linear(in_features=4096, out_features=7, bias=True)\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#accuracy of the model\n",
        "from tqdm import tqdm\n",
        "def multiclass_accuracy(y_pred,y_true):\n",
        "    top_p,top_class = y_pred.topk(1,dim = 1)\n",
        "    equals = top_class == y_true.view(*top_class.shape)\n",
        "    return torch.mean(equals.type(torch.FloatTensor))"
      ],
      "metadata": {
        "id": "mpHoVI9VwEuP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#building the train and eval functions (training the model on the training and on the validation set)\n",
        "def train_model(model, dataloader, optimizer, current_epoch):\n",
        "\n",
        "  model.train()\n",
        "  total_loss = 0.0\n",
        "  total_acc = 0.0\n",
        "  tk = tqdm(dataloader, desc='EPOCH' + '[TRAIN]' + str(current_epoch + 1) + \"/\" + str(epochs))\n",
        "\n",
        "  for t, data in enumerate(tk):\n",
        "    images, labels = data\n",
        "    images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    logits = model(images)\n",
        "    loss = nn.CrossEntropyLoss()(logits,  labels)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    total_loss += loss.item()\n",
        "    total_acc += multiclass_accuracy(logits, labels)\n",
        "    tk.set_postfix({'loss': float(total_loss/(t+1)),'acc': float(total_acc/(t+1))})\n",
        "  return total_loss/len(dataloader), total_acc / len(dataloader)\n",
        "\n",
        "def eval_model(model, dataloader, current_epoch):\n",
        "\n",
        "  model.eval()\n",
        "  total_loss = 0.0\n",
        "  total_acc = 0.0\n",
        "  tk = tqdm(dataloader, desc='EPOCH' + '[VALID]' + str(current_epoch + 1) + \"/\" + str(epochs))\n",
        "\n",
        "  for t, data in enumerate(tk):\n",
        "    images, labels = data\n",
        "    images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "    logits = model(images)\n",
        "    loss = nn.CrossEntropyLoss()(logits,  labels)\n",
        "\n",
        "    total_loss += loss.item()\n",
        "    total_acc += multiclass_accuracy(logits, labels)\n",
        "    tk.set_postfix({'loss': float(total_loss/(t+1)),'acc': float(total_acc/(t+1))})\n",
        "  return total_loss/len(dataloader), total_acc / len(dataloader)\n",
        "\n",
        "def test_model(model, dataloader, current_epoch=1):\n",
        "\n",
        "  model.eval()\n",
        "  total_loss = 0.0\n",
        "  total_acc = 0.0\n",
        "  tk = tqdm(dataloader, desc='EPOCH' + '[TEST]' + str(current_epoch + 1) + \"/\" + str(epochs))\n",
        "\n",
        "  for t, data in enumerate(tk):\n",
        "    images, labels = data\n",
        "    images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "    logits = model(images)\n",
        "    loss = nn.CrossEntropyLoss()(logits,  labels)\n",
        "\n",
        "    total_loss += loss.item()\n",
        "    total_acc += multiclass_accuracy(logits, labels)\n",
        "    tk.set_postfix({'loss': float(total_loss/(t+1)),'acc': float(total_acc/(t+1))})\n",
        "  return total_loss/len(dataloader), total_acc / len(dataloader)"
      ],
      "metadata": {
        "id": "5gmlWz2fwy9Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#now let's train the model\n",
        "from torch import optim\n",
        "# optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "optimizer = optim.SGD(model.parameters(), lr=lr, momentum=0.5, weight_decay=1e-2, nesterov=True)"
      ],
      "metadata": {
        "id": "rzj7fwZoxLN_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_valid_loss = np.Inf\n",
        "train_losses = []\n",
        "validation_losses = []\n",
        "for i in range(epochs):\n",
        "  train_loss, train_acc = train_model(model, trainloader, optimizer, i)\n",
        "  valid_loss, valid_acc = eval_model(model, validloader, i)\n",
        "  train_losses.append(train_loss)\n",
        "  validation_losses.append(valid_loss)\n",
        "\n",
        "  if valid_loss < best_valid_loss:\n",
        "    torch.save(model.state_dict(), os.path.join(data_path, 'VGG16-Adam.h5'))\n",
        "    print('SAVED BEST WEIGHTS')\n",
        "    best_valid_loss = valid_loss\n",
        "print()\n",
        "print()\n",
        "print('accuracy on the training set: ', float(train_acc))\n",
        "print('accuracy on the validation set: ', float(valid_acc))"
      ],
      "metadata": {
        "id": "AGamEDaZyPxv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "644e28b4-0e6b-4740-ca9c-b9deb07a7fe4"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "EPOCH[TRAIN]1/50: 100%|██████████| 386/386 [14:12<00:00,  2.21s/it, loss=1.81, acc=0.279]\n",
            "EPOCH[VALID]1/50: 100%|██████████| 29/29 [00:07<00:00,  3.67it/s, loss=1.68, acc=0.347]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SAVED BEST WEIGHTS\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "EPOCH[TRAIN]2/50: 100%|██████████| 386/386 [14:11<00:00,  2.20s/it, loss=1.63, acc=0.371]\n",
            "EPOCH[VALID]2/50: 100%|██████████| 29/29 [00:07<00:00,  3.74it/s, loss=1.58, acc=0.401]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SAVED BEST WEIGHTS\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "EPOCH[TRAIN]3/50: 100%|██████████| 386/386 [13:59<00:00,  2.17s/it, loss=1.53, acc=0.412]\n",
            "EPOCH[VALID]3/50: 100%|██████████| 29/29 [00:07<00:00,  3.72it/s, loss=1.5, acc=0.43]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SAVED BEST WEIGHTS\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "EPOCH[TRAIN]4/50: 100%|██████████| 386/386 [13:53<00:00,  2.16s/it, loss=1.47, acc=0.442]\n",
            "EPOCH[VALID]4/50: 100%|██████████| 29/29 [00:07<00:00,  3.74it/s, loss=1.5, acc=0.428]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SAVED BEST WEIGHTS\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "EPOCH[TRAIN]5/50: 100%|██████████| 386/386 [13:49<00:00,  2.15s/it, loss=1.41, acc=0.465]\n",
            "EPOCH[VALID]5/50: 100%|██████████| 29/29 [00:07<00:00,  3.89it/s, loss=1.34, acc=0.488]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SAVED BEST WEIGHTS\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "EPOCH[TRAIN]6/50: 100%|██████████| 386/386 [13:42<00:00,  2.13s/it, loss=1.37, acc=0.48]\n",
            "EPOCH[VALID]6/50: 100%|██████████| 29/29 [00:07<00:00,  3.95it/s, loss=1.38, acc=0.47]\n",
            "EPOCH[TRAIN]7/50: 100%|██████████| 386/386 [13:17<00:00,  2.07s/it, loss=1.33, acc=0.492]\n",
            "EPOCH[VALID]7/50: 100%|██████████| 29/29 [00:07<00:00,  3.75it/s, loss=1.32, acc=0.489]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SAVED BEST WEIGHTS\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "EPOCH[TRAIN]8/50: 100%|██████████| 386/386 [13:43<00:00,  2.13s/it, loss=1.3, acc=0.505]\n",
            "EPOCH[VALID]8/50: 100%|██████████| 29/29 [00:07<00:00,  3.67it/s, loss=1.28, acc=0.513]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SAVED BEST WEIGHTS\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "EPOCH[TRAIN]9/50:  10%|▉         | 37/386 [01:23<11:55,  2.05s/it, loss=1.3, acc=0.502]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_the_loss_curve(epochs, training_losses, validation_losses):\n",
        "  \"\"\"Plot a curve of loss vs. epoch.\"\"\"\n",
        "  epochs = list(range(1, epochs + 1))\n",
        "  plt.figure(figsize=(10, 5))\n",
        "  plt.xlabel(\"Epoch\")\n",
        "  plt.ylabel(\"Cross Entropy losses\")\n",
        "\n",
        "  plt.plot(epochs[1:], training_losses[1:], label=\"Training Loss\")\n",
        "  plt.plot(epochs[1:], validation_losses[1:], label=\"Validation Loss\")\n",
        "  plt.legend()\n",
        "  \n",
        "  # We're not going to plot the first epoch, since the loss on the first epoch\n",
        "  # is often substantially greater than the loss for other epochs.\n",
        "  merged_losses = training_losses[1:] + validation_losses[1:]\n",
        "  highest_loss = max(merged_losses)\n",
        "  lowest_loss = min(merged_losses)\n",
        "  delta = highest_loss - lowest_loss\n",
        "  print(delta)\n",
        "\n",
        "  top_of_y_axis = highest_loss + (delta * 0.05)\n",
        "  bottom_of_y_axis = lowest_loss - (delta * 0.05)\n",
        "  plt.title('loss curve') \n",
        "  plt.ylim([bottom_of_y_axis, top_of_y_axis])\n",
        "  plt.show()  "
      ],
      "metadata": {
        "id": "2SWd3tteW85B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_the_loss_curve(epochs, train_losses, validation_losses)"
      ],
      "metadata": {
        "id": "iiwO-lyAXB4T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_acc = test_model(model, testloader)\n",
        "print()\n",
        "print('accuracy on the test set: ', float(test_acc))"
      ],
      "metadata": {
        "id": "jyfdP1m3g9J6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}