{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kalebmes/Facial-Expression-Recognition/blob/main/Models/Resnet_50_(Transfer_learning).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_hbOvpcyD-7H",
        "outputId": "8a417170-c5bf-48c2-d8a2-78e81a7e4e4f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "#mount your drive first - you can do it once\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "1O_7o8yiL7fZ"
      },
      "outputs": [],
      "source": [
        "#importing necessary modules\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from PIL import Image\n",
        "import os\n",
        "import torchvision.datasets as dset\n",
        "import torchvision.transforms as T"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1AtbkaA7Ozsy",
        "outputId": "d9048024-c7b5-46c1-872d-b2d89c38d323"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU available\n"
          ]
        }
      ],
      "source": [
        "#hyperparameters start form \n",
        "lr = 1e-3\n",
        "batch_size = 128\n",
        "epochs = 50\n",
        "\n",
        "#device\n",
        "device = 'cpu'\n",
        "if torch.cuda.is_available():\n",
        "  device = 'cuda'\n",
        "  print('GPU available')\n",
        "else:\n",
        "  print('training is done on CPU')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "mDauIl3KPaE4"
      },
      "outputs": [],
      "source": [
        "#now let's load the dataset into the 'dataloader' package of pytorch\n",
        "from torchvision.datasets import ImageFolder\n",
        "import torchvision.transforms as T"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "3Mn5MAN8SsUR"
      },
      "outputs": [],
      "source": [
        "#first step is creating an augmentation cell using transforms of pytorch\n",
        "train_augs = T.Compose([T.RandomHorizontalFlip(p=0.5), \n",
        "                        T.RandomRotation(degrees=(-10, +10)),\n",
        "                        T.RandomAffine(degrees=(-10, +10), translate=(0.1, 0.2)),\n",
        "                        T.Resize((48, 48)),\n",
        "                        T.ToTensor()])\n",
        "\n",
        "valid_augs = T.Compose([T.ToTensor()])\n",
        "\n",
        "test_augs = T.Compose([T.ToTensor()])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "xJKiovhRb1Yz"
      },
      "outputs": [],
      "source": [
        "data_path = '/content/drive/MyDrive/datasets'\n",
        "train_path = os.path.join(data_path, 'train')\n",
        "validation_path = os.path.join(data_path, 'validation')\n",
        "test_path = os.path.join(data_path, 'test')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-iRhgKwIS3jX",
        "outputId": "7c6359ea-5cd5-4b6c-fb0f-cd484993df80"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total no. of examples in trainset : 49297\n",
            "Total no. of examples in validset : 3599\n",
            "Total no. of examples in testset : 3589\n"
          ]
        }
      ],
      "source": [
        "trainset = ImageFolder(train_path, transform=train_augs)\n",
        "validset = ImageFolder(validation_path, transform=valid_augs)\n",
        "testset = ImageFolder(test_path, transform=test_augs)\n",
        "print(f\"Total no. of examples in trainset : {len(trainset)}\")\n",
        "print(f\"Total no. of examples in validset : {len(validset)}\")\n",
        "print(f\"Total no. of examples in testset : {len(testset)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "SrM66qzviRg6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd8e4b38-c766-43f3-b935-73a246288e6a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'anger': 0, 'disgust': 1, 'fear': 2, 'happy': 3, 'neutral': 4, 'sad': 5, 'surprise': 6}\n"
          ]
        }
      ],
      "source": [
        "print(trainset.class_to_idx)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "4KPvBCwgiWqI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316
        },
        "outputId": "236c0cbe-d9bb-4910-f4f7-76fc38471e04"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "chosen index:  11999\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, '2')"
            ]
          },
          "metadata": {},
          "execution_count": 26
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "#we can view some images and their labels\n",
        "import matplotlib.pyplot as plt\n",
        "idx = np.random.randint(low=0, high=len(trainset)-1)\n",
        "print('chosen index: ', idx)\n",
        "image, label = trainset[idx] # the image has format of h, w, c -> so it have to be reshaped\n",
        "plt.imshow(image.permute(1, 2, 0))\n",
        "plt.title(label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "5BU0SeIctamL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df2f2d78-8278-447e-abe5-8e120338f3b7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total batches in trainloader:  386 , validloader:  29 , and testloader 3589\n"
          ]
        }
      ],
      "source": [
        "#now let's read the dataset using pytorch's dataloader\n",
        "trainloader = DataLoader(trainset, batch_size=batch_size, shuffle=True)\n",
        "validloader = DataLoader(validset, batch_size=batch_size)\n",
        "testloader = DataLoader(testset)\n",
        "print('total batches in trainloader: ', len(trainloader), ', validloader: ', len(validloader), ', and testloader', len(testloader))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "HPjkKbNXsyhM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3ff9dd57-6119-40a5-92d1-85709d83e739"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "shape of a batch of images: torch.Size([128, 3, 48, 48])\n",
            "shape of a batch of labels: torch.Size([128])\n"
          ]
        }
      ],
      "source": [
        "#checking the shapes of each batch\n",
        "for images, labels in trainloader:\n",
        "  break\n",
        "print(f'shape of a batch of images: {images.shape}')\n",
        "print(f'shape of a batch of labels: {labels.shape}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "gfjbdWSG1s4x"
      },
      "outputs": [],
      "source": [
        "from torchvision import models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "mSG4M3c2wAiw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "2ee58e0833fb4e55aed0267e8d3ac815",
            "89ae3c7558a44c768c7f6dfbe6c6cbe5",
            "d7969e9911634924a1d331334ad1314d",
            "ae1c3929962241e5b942de7ba781ba2a",
            "76b7f7ae27a24a8f9ad027b79d6342d2",
            "44c4d08d87d4413184f66f37b995d5ba",
            "4c055d3a70f145d88fca6cc606046c51",
            "4ceed10332834ddabc690de5f0c54d3d",
            "8e650c2f287d4e9bb5ec4039279ad5fa",
            "f50640a58c35405cb19eb18f68b7ca65",
            "74b82f0f011749be9ae08be86c426326"
          ]
        },
        "outputId": "54733029-8c42-4264-e1a4-3ee11c77c543"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0.00/97.8M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2ee58e0833fb4e55aed0267e8d3ac815"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ResNet(\n",
              "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (relu): ReLU(inplace=True)\n",
              "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "  (layer1): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (3): Bottleneck(\n",
              "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (layer3): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (3): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (4): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (5): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (layer4): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "  (fc): Sequential(\n",
              "    (dropout1): Dropout(p=0.5, inplace=False)\n",
              "    (fc1): Linear(in_features=2048, out_features=4096, bias=True)\n",
              "    (relu1): ReLU(inplace=True)\n",
              "    (dropout2): Dropout(p=0.5, inplace=False)\n",
              "    (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "    (relu2): ReLU(inplace=True)\n",
              "    (dropout3): Dropout(p=0.5, inplace=False)\n",
              "    (fc4): Linear(in_features=1024, out_features=7, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "from collections import OrderedDict\n",
        "\n",
        "model = models.resnet50(pretrained=True)\n",
        "\n",
        "num_in_features = model.fc.in_features\n",
        "#we can get the number of input features as follows\n",
        "# num_in_features = model.get_classifier().\n",
        "# for param in model.parameters():\n",
        "#   param.requires_grad = False\n",
        "\n",
        "# #let's also add some fully connected layer to demonstrate representation learning\n",
        "model.fc = nn.Sequential(OrderedDict([\n",
        "    ('dropout1', nn.Dropout(p=0.5)), \n",
        "    ('fc1', nn.Linear(num_in_features, 4096)), \n",
        "    ('relu1', nn.ReLU(inplace=True)), \n",
        "    ('dropout2', nn.Dropout(p=0.5)), \n",
        "    ('fc2', nn.Linear(4096, 1024)), \n",
        "    ('relu2', nn.ReLU(inplace=True)), \n",
        "    ('dropout3', nn.Dropout(p=0.5)), \n",
        "    ('fc4', nn.Linear(1024, 7)), \n",
        "]))\n",
        "model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "mpHoVI9VwEuP"
      },
      "outputs": [],
      "source": [
        "#accuracy of the model\n",
        "from tqdm import tqdm\n",
        "def multiclass_accuracy(y_pred,y_true):\n",
        "    top_p,top_class = y_pred.topk(1,dim = 1)\n",
        "    equals = top_class == y_true.view(*top_class.shape)\n",
        "    return torch.mean(equals.type(torch.FloatTensor))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "5gmlWz2fwy9Q"
      },
      "outputs": [],
      "source": [
        "#building the train and eval functions (training the model on the training and on the validation set)\n",
        "def train_model(model, dataloader, optimizer, current_epoch):\n",
        "\n",
        "  model.train()\n",
        "  total_loss = 0.0\n",
        "  total_acc = 0.0\n",
        "  tk = tqdm(dataloader, desc='EPOCH' + '[TRAIN]' + str(current_epoch + 1) + \"/\" + str(epochs))\n",
        "\n",
        "  for t, data in enumerate(tk):\n",
        "    images, labels = data\n",
        "    images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    logits = model(images)\n",
        "    loss = nn.CrossEntropyLoss()(logits,  labels)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    total_loss += loss.item()\n",
        "    total_acc += multiclass_accuracy(logits, labels)\n",
        "    tk.set_postfix({'loss': float(total_loss/(t+1)),'acc': float(total_acc/(t+1))})\n",
        "  return total_loss/len(dataloader), total_acc / len(dataloader)\n",
        "\n",
        "def eval_model(model, dataloader, current_epoch):\n",
        "\n",
        "  model.eval()\n",
        "  total_loss = 0.0\n",
        "  total_acc = 0.0\n",
        "  tk = tqdm(dataloader, desc='EPOCH' + '[VALID]' + str(current_epoch + 1) + \"/\" + str(epochs))\n",
        "\n",
        "  for t, data in enumerate(tk):\n",
        "    images, labels = data\n",
        "    images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "    logits = model(images)\n",
        "    loss = nn.CrossEntropyLoss()(logits,  labels)\n",
        "\n",
        "    total_loss += loss.item()\n",
        "    total_acc += multiclass_accuracy(logits, labels)\n",
        "    tk.set_postfix({'loss': float(total_loss/(t+1)),'acc': float(total_acc/(t+1))})\n",
        "  return total_loss/len(dataloader), total_acc / len(dataloader)\n",
        "\n",
        "def test_model(model, dataloader, current_epoch=1):\n",
        "\n",
        "  model.eval()\n",
        "  total_loss = 0.0\n",
        "  total_acc = 0.0\n",
        "  tk = tqdm(dataloader, desc='EPOCH' + '[TEST]' + str(current_epoch) + \"/\" + str(1))\n",
        "\n",
        "  for t, data in enumerate(tk):\n",
        "    images, labels = data\n",
        "    images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "    logits = model(images)\n",
        "    loss = nn.CrossEntropyLoss()(logits,  labels)\n",
        "\n",
        "    total_loss += loss.item()\n",
        "    total_acc += multiclass_accuracy(logits, labels)\n",
        "    tk.set_postfix({'loss': float(total_loss/(t+1)),'acc': float(total_acc/(t+1))})\n",
        "  return total_loss/len(dataloader), total_acc / len(dataloader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "rzj7fwZoxLN_"
      },
      "outputs": [],
      "source": [
        "#now let's train the model\n",
        "from torch import optim\n",
        "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "# optimizer = optim.SGD(model.parameters(), lr=lr, momentum=0.9, weight_decay=1e-4, nesterov=True) # gives much better accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AGamEDaZyPxv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d2ebd9e-8ea5-42a7-b687-fc868de05204"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "EPOCH[TRAIN]1/50: 100%|██████████| 386/386 [4:13:35<00:00, 39.42s/it, loss=1.64, acc=0.358]\n",
            "EPOCH[VALID]1/50: 100%|██████████| 29/29 [17:57<00:00, 37.16s/it, loss=1.46, acc=0.453]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SAVED BEST WEIGHTS\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "EPOCH[TRAIN]2/50: 100%|██████████| 386/386 [11:53<00:00,  1.85s/it, loss=1.47, acc=0.441]\n",
            "EPOCH[VALID]2/50: 100%|██████████| 29/29 [00:07<00:00,  4.03it/s, loss=1.38, acc=0.472]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SAVED BEST WEIGHTS\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "EPOCH[TRAIN]3/50: 100%|██████████| 386/386 [11:38<00:00,  1.81s/it, loss=1.37, acc=0.485]\n",
            "EPOCH[VALID]3/50: 100%|██████████| 29/29 [00:06<00:00,  4.17it/s, loss=1.29, acc=0.504]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SAVED BEST WEIGHTS\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "EPOCH[TRAIN]4/50:  60%|██████    | 232/386 [06:55<04:29,  1.75s/it, loss=1.35, acc=0.494]"
          ]
        }
      ],
      "source": [
        "best_valid_loss = np.Inf\n",
        "train_losses = []\n",
        "validation_losses = []\n",
        "# model_path = '/content/drive/MyDrive/ML Project Folder/Models'\n",
        "for i in range(epochs):\n",
        "  train_loss, train_acc = train_model(model, trainloader, optimizer, i)\n",
        "  valid_loss, valid_acc = eval_model(model, validloader, i)\n",
        "  train_losses.append(train_loss)\n",
        "  validation_losses.append(valid_loss)\n",
        "\n",
        "  if valid_loss < best_valid_loss:\n",
        "    torch.save(model.state_dict(), os.path.join(data_path, 'resnet-50-Adam (transfer_learning).h5'))\n",
        "    print('SAVED BEST WEIGHTS')\n",
        "    best_valid_loss = valid_loss\n",
        "print()\n",
        "print()\n",
        "print('accuracy on the training set: ', float(train_acc))\n",
        "print('accuracy on the validation set: ', float(valid_acc))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kCVDIV3QThFV"
      },
      "outputs": [],
      "source": [
        "def plot_the_loss_curve(epochs, training_losses, validation_losses):\n",
        "  \"\"\"Plot a curve of loss vs. epoch.\"\"\"\n",
        "  epochs = list(range(1, epochs + 1))\n",
        "  plt.figure(figsize=(10, 5))\n",
        "  plt.xlabel(\"Epoch\")\n",
        "  plt.ylabel(\"Cross Entropy losses\")\n",
        "\n",
        "  plt.plot(epochs[1:], training_losses[1:], label=\"Training Loss\")\n",
        "  plt.plot(epochs[1:], validation_losses[1:], label=\"Validation Loss\")\n",
        "  plt.legend()\n",
        "  \n",
        "  # We're not going to plot the first epoch, since the loss on the first epoch\n",
        "  # is often substantially greater than the loss for other epochs.\n",
        "  merged_losses = training_losses[1:] + validation_losses[1:]\n",
        "  highest_loss = max(merged_losses)\n",
        "  lowest_loss = min(merged_losses)\n",
        "  delta = highest_loss - lowest_loss\n",
        "\n",
        "  top_of_y_axis = highest_loss + (delta * 0.05)\n",
        "  bottom_of_y_axis = lowest_loss - (delta * 0.05)\n",
        "  plt.title('loss curve') \n",
        "  plt.ylim([bottom_of_y_axis, top_of_y_axis])\n",
        "  plt.show()  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OUOT2OUi8D57"
      },
      "outputs": [],
      "source": [
        "plot_the_loss_curve(epochs, train_losses, validation_losses)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Resnet_50 (Transfer learning).ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "2ee58e0833fb4e55aed0267e8d3ac815": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_89ae3c7558a44c768c7f6dfbe6c6cbe5",
              "IPY_MODEL_d7969e9911634924a1d331334ad1314d",
              "IPY_MODEL_ae1c3929962241e5b942de7ba781ba2a"
            ],
            "layout": "IPY_MODEL_76b7f7ae27a24a8f9ad027b79d6342d2"
          }
        },
        "89ae3c7558a44c768c7f6dfbe6c6cbe5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_44c4d08d87d4413184f66f37b995d5ba",
            "placeholder": "​",
            "style": "IPY_MODEL_4c055d3a70f145d88fca6cc606046c51",
            "value": "100%"
          }
        },
        "d7969e9911634924a1d331334ad1314d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4ceed10332834ddabc690de5f0c54d3d",
            "max": 102530333,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8e650c2f287d4e9bb5ec4039279ad5fa",
            "value": 102530333
          }
        },
        "ae1c3929962241e5b942de7ba781ba2a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f50640a58c35405cb19eb18f68b7ca65",
            "placeholder": "​",
            "style": "IPY_MODEL_74b82f0f011749be9ae08be86c426326",
            "value": " 97.8M/97.8M [00:00&lt;00:00, 176MB/s]"
          }
        },
        "76b7f7ae27a24a8f9ad027b79d6342d2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "44c4d08d87d4413184f66f37b995d5ba": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4c055d3a70f145d88fca6cc606046c51": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4ceed10332834ddabc690de5f0c54d3d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8e650c2f287d4e9bb5ec4039279ad5fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f50640a58c35405cb19eb18f68b7ca65": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "74b82f0f011749be9ae08be86c426326": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}