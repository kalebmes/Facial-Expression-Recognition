{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Resnet_50.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "685c7e367f964cc380570bc8f3542fa4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_62b54b3775d144eb81d0a53a495739b4",
              "IPY_MODEL_d9d98739982b4b5dadedf27e150deb52",
              "IPY_MODEL_c6d12f1b80ff41a3a19b25125f3b5eee"
            ],
            "layout": "IPY_MODEL_b5960034ffaf4284bcb2be14386361a4"
          }
        },
        "62b54b3775d144eb81d0a53a495739b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0a392b9c6cf24ec69ef87d3ee234d8ae",
            "placeholder": "​",
            "style": "IPY_MODEL_07582776533641e39fbabb8ec285e742",
            "value": "100%"
          }
        },
        "d9d98739982b4b5dadedf27e150deb52": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eecec366da4144bb959290ef8f2684bf",
            "max": 102530333,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1f58169883d04c8f9b2a3bfa7ee2b179",
            "value": 102530333
          }
        },
        "c6d12f1b80ff41a3a19b25125f3b5eee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2afcf0b929b84b0eb3977496bb408a23",
            "placeholder": "​",
            "style": "IPY_MODEL_dca7dbcea9534b51a96012135960abc4",
            "value": " 97.8M/97.8M [00:03&lt;00:00, 31.3MB/s]"
          }
        },
        "b5960034ffaf4284bcb2be14386361a4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0a392b9c6cf24ec69ef87d3ee234d8ae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "07582776533641e39fbabb8ec285e742": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "eecec366da4144bb959290ef8f2684bf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1f58169883d04c8f9b2a3bfa7ee2b179": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2afcf0b929b84b0eb3977496bb408a23": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dca7dbcea9534b51a96012135960abc4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kalebmes/Facial-Expression-Recognition/blob/main/Models/Resnet_50.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#mount your drive first - you can do it once\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "_hbOvpcyD-7H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e0798652-249a-4f7e-f446-09e5f8b61227"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#importing necessary modules\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from PIL import Image\n",
        "import os\n",
        "import torchvision.datasets as dset\n",
        "import torchvision.transforms as T"
      ],
      "metadata": {
        "id": "1O_7o8yiL7fZ"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#hyperparameters start form \n",
        "lr = 1e-3\n",
        "batch_size = 128\n",
        "epochs = 50\n",
        "\n",
        "#device\n",
        "device = 'cpu'\n",
        "if torch.cuda.is_available():\n",
        "  device = 'cuda'\n",
        "  print('GPU available')\n",
        "else:\n",
        "  print('training is done on CPU')"
      ],
      "metadata": {
        "id": "1AtbkaA7Ozsy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "997d920c-8dd2-414f-f0f1-01188580bc20"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU available\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#now let's load the dataset into the 'dataloader' package of pytorch\n",
        "from torchvision.datasets import ImageFolder\n",
        "import torchvision.transforms as T"
      ],
      "metadata": {
        "id": "mDauIl3KPaE4"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#first step is creating an augmentation cell using transforms of pytorch\n",
        "train_augs = T.Compose([T.RandomHorizontalFlip(p=0.5), \n",
        "                        T.RandomRotation(degrees=(-10, +10)),\n",
        "                        T.RandomAffine(degrees=(-10, +10), translate=(0.1, 0.2)),\n",
        "                        T.Resize((48, 48)),\n",
        "                        T.ToTensor()])\n",
        "\n",
        "valid_augs = T.Compose([T.ToTensor()])\n",
        "\n",
        "test_augs = T.Compose([T.ToTensor()])"
      ],
      "metadata": {
        "id": "3Mn5MAN8SsUR"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_path = '/content/drive/MyDrive/datasets'\n",
        "train_path = os.path.join(data_path, 'train')\n",
        "validation_path = os.path.join(data_path, 'validation')\n",
        "test_path = os.path.join(data_path, 'test')"
      ],
      "metadata": {
        "id": "xJKiovhRb1Yz"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainset = ImageFolder(train_path, transform=train_augs)\n",
        "validset = ImageFolder(validation_path, transform=valid_augs)\n",
        "testset = ImageFolder(test_path, transform=test_augs)\n",
        "print(f\"Total no. of examples in trainset : {len(trainset)}\")\n",
        "print(f\"Total no. of examples in validset : {len(validset)}\")\n",
        "print(f\"Total no. of examples in testset : {len(testset)}\")"
      ],
      "metadata": {
        "id": "-iRhgKwIS3jX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "00bd3bee-9e9d-4516-ecb1-98ebc9170bed"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total no. of examples in trainset : 49297\n",
            "Total no. of examples in validset : 3599\n",
            "Total no. of examples in testset : 3589\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(trainset.class_to_idx)"
      ],
      "metadata": {
        "id": "SrM66qzviRg6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b378fd39-466d-48bf-f5a5-5834e4bef4c5"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'anger': 0, 'disgust': 1, 'fear': 2, 'happy': 3, 'neutral': 4, 'sad': 5, 'surprise': 6}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#we can view some images and their labels\n",
        "import matplotlib.pyplot as plt\n",
        "idx = np.random.randint(low=0, high=len(trainset)-1)\n",
        "print('chosen index: ', idx)\n",
        "image, label = trainset[idx] # the image has format of h, w, c -> so it have to be reshaped\n",
        "plt.imshow(image.permute(1, 2, 0))\n",
        "plt.title(label)"
      ],
      "metadata": {
        "id": "4KPvBCwgiWqI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316
        },
        "outputId": "4f601568-cfa9-4616-f318-84df3008a366"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "chosen index:  48878\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, '6')"
            ]
          },
          "metadata": {},
          "execution_count": 9
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#now let's read the dataset using pytorch's dataloader\n",
        "trainloader = DataLoader(trainset, batch_size=batch_size, shuffle=True)\n",
        "validloader = DataLoader(validset, batch_size=batch_size)\n",
        "testloader = DataLoader(testset)\n",
        "print('total batches in trainloader: ', len(trainloader), ', validloader: ', len(validloader), ', and testloader', len(testloader))"
      ],
      "metadata": {
        "id": "5BU0SeIctamL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "05dbeee9-5ecd-4e70-99bd-029facb6ea16"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total batches in trainloader:  386 , validloader:  29 , and testloader 3589\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#checking the shapes of each batch\n",
        "for images, labels in trainloader:\n",
        "  break\n",
        "print(f'shape of a batch of images: {images.shape}')\n",
        "print(f'shape of a batch of labels: {labels.shape}')"
      ],
      "metadata": {
        "id": "HPjkKbNXsyhM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e3a0bec7-ea10-4150-d487-67e7284a014d"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "shape of a batch of images: torch.Size([128, 3, 48, 48])\n",
            "shape of a batch of labels: torch.Size([128])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import models"
      ],
      "metadata": {
        "id": "gfjbdWSG1s4x"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = models.resnet50(pretrained=True)\n",
        "#modify the last layer -> to have a linear layer whose output is 7\n",
        "in_features = model.fc.in_features\n",
        "model.fc = nn.Linear(in_features, 7)\n",
        "model.to(device)"
      ],
      "metadata": {
        "id": "mSG4M3c2wAiw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "685c7e367f964cc380570bc8f3542fa4",
            "62b54b3775d144eb81d0a53a495739b4",
            "d9d98739982b4b5dadedf27e150deb52",
            "c6d12f1b80ff41a3a19b25125f3b5eee",
            "b5960034ffaf4284bcb2be14386361a4",
            "0a392b9c6cf24ec69ef87d3ee234d8ae",
            "07582776533641e39fbabb8ec285e742",
            "eecec366da4144bb959290ef8f2684bf",
            "1f58169883d04c8f9b2a3bfa7ee2b179",
            "2afcf0b929b84b0eb3977496bb408a23",
            "dca7dbcea9534b51a96012135960abc4"
          ]
        },
        "outputId": "761b1e20-01e2-4524-8b91-1f4f652b6a35"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0.00/97.8M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "685c7e367f964cc380570bc8f3542fa4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ResNet(\n",
              "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (relu): ReLU(inplace=True)\n",
              "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "  (layer1): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (3): Bottleneck(\n",
              "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (layer3): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (3): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (4): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (5): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (layer4): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "  (fc): Linear(in_features=2048, out_features=7, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#accuracy of the model\n",
        "from tqdm import tqdm\n",
        "def multiclass_accuracy(y_pred,y_true):\n",
        "    top_p,top_class = y_pred.topk(1,dim = 1)\n",
        "    equals = top_class == y_true.view(*top_class.shape)\n",
        "    return torch.mean(equals.type(torch.FloatTensor))"
      ],
      "metadata": {
        "id": "mpHoVI9VwEuP"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#building the train and eval functions (training the model on the training and on the validation set)\n",
        "def train_model(model, dataloader, optimizer, current_epoch):\n",
        "\n",
        "  model.train()\n",
        "  total_loss = 0.0\n",
        "  total_acc = 0.0\n",
        "  tk = tqdm(dataloader, desc='EPOCH' + '[TRAIN]' + str(current_epoch + 1) + \"/\" + str(epochs))\n",
        "\n",
        "  for t, data in enumerate(tk):\n",
        "    images, labels = data\n",
        "    images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    logits = model(images)\n",
        "    loss = nn.CrossEntropyLoss()(logits,  labels)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    total_loss += loss.item()\n",
        "    total_acc += multiclass_accuracy(logits, labels)\n",
        "    tk.set_postfix({'loss': float(total_loss/(t+1)),'acc': float(total_acc/(t+1))})\n",
        "  return total_loss/len(dataloader), total_acc / len(dataloader)\n",
        "\n",
        "def eval_model(model, dataloader, current_epoch):\n",
        "\n",
        "  model.eval()\n",
        "  total_loss = 0.0\n",
        "  total_acc = 0.0\n",
        "  tk = tqdm(dataloader, desc='EPOCH' + '[VALID]' + str(current_epoch + 1) + \"/\" + str(epochs))\n",
        "\n",
        "  for t, data in enumerate(tk):\n",
        "    images, labels = data\n",
        "    images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "    logits = model(images)\n",
        "    loss = nn.CrossEntropyLoss()(logits,  labels)\n",
        "\n",
        "    total_loss += loss.item()\n",
        "    total_acc += multiclass_accuracy(logits, labels)\n",
        "    tk.set_postfix({'loss': float(total_loss/(t+1)),'acc': float(total_acc/(t+1))})\n",
        "  return total_loss/len(dataloader), total_acc / len(dataloader)\n",
        "\n",
        "def test_model(model, dataloader, current_epoch=1):\n",
        "\n",
        "  model.eval()\n",
        "  total_loss = 0.0\n",
        "  total_acc = 0.0\n",
        "  tk = tqdm(dataloader, desc='EPOCH' + '[TEST]' + str(current_epoch) + \"/\" + str(1))\n",
        "\n",
        "  for t, data in enumerate(tk):\n",
        "    images, labels = data\n",
        "    images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "    logits = model(images)\n",
        "    loss = nn.CrossEntropyLoss()(logits,  labels)\n",
        "\n",
        "    total_loss += loss.item()\n",
        "    total_acc += multiclass_accuracy(logits, labels)\n",
        "    tk.set_postfix({'loss': float(total_loss/(t+1)),'acc': float(total_acc/(t+1))})\n",
        "  return total_loss/len(dataloader), total_acc / len(dataloader)"
      ],
      "metadata": {
        "id": "5gmlWz2fwy9Q"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#now let's train the model\n",
        "from torch import optim\n",
        "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "# optimizer = optim.SGD(model.parameters(), lr=lr, momentum=0.5, weight_decay=1e-2, nesterov=True) "
      ],
      "metadata": {
        "id": "rzj7fwZoxLN_"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_valid_loss = np.Inf\n",
        "train_losses = []\n",
        "validation_losses = []\n",
        "for i in range(epochs):\n",
        "  train_loss, train_acc = train_model(model, trainloader, optimizer, i)\n",
        "  valid_loss, valid_acc = eval_model(model, validloader, i)\n",
        "  train_losses.append(train_loss)\n",
        "  validation_losses.append(valid_loss)\n",
        "\n",
        "  if valid_loss < best_valid_loss:\n",
        "    torch.save(model.state_dict(), os.path.join(data_path, 'resnet-50-adam.h5'))\n",
        "    print('SAVED BEST WEIGHTS')\n",
        "    best_valid_loss = valid_loss\n",
        "print()\n",
        "print()\n",
        "print('accuracy on the training set: ', float(train_acc))\n",
        "print('accuracy on the validation set: ', float(valid_acc))"
      ],
      "metadata": {
        "id": "AGamEDaZyPxv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e16fbf91-0cab-409c-bb9c-2a275c25f64c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "EPOCH[TRAIN]1/50: 100%|██████████| 386/386 [4:14:44<00:00, 39.60s/it, loss=1.46, acc=0.446]\n",
            "EPOCH[VALID]1/50: 100%|██████████| 29/29 [17:31<00:00, 36.26s/it, loss=1.39, acc=0.479]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SAVED BEST WEIGHTS\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "EPOCH[TRAIN]2/50: 100%|██████████| 386/386 [11:45<00:00,  1.83s/it, loss=1.24, acc=0.532]\n",
            "EPOCH[VALID]2/50: 100%|██████████| 29/29 [00:07<00:00,  3.91it/s, loss=1.25, acc=0.544]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SAVED BEST WEIGHTS\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "EPOCH[TRAIN]3/50: 100%|██████████| 386/386 [11:41<00:00,  1.82s/it, loss=1.18, acc=0.555]\n",
            "EPOCH[VALID]3/50: 100%|██████████| 29/29 [00:07<00:00,  4.06it/s, loss=1.34, acc=0.502]\n",
            "EPOCH[TRAIN]4/50:  59%|█████▉    | 227/386 [06:46<05:05,  1.92s/it, loss=1.14, acc=0.571]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_the_loss_curve(epochs, training_losses, validation_losses):\n",
        "  \"\"\"Plot a curve of loss vs. epoch.\"\"\"\n",
        "  epochs = list(range(1, epochs + 1))\n",
        "  plt.figure(figsize=(10, 5))\n",
        "  plt.xlabel(\"Epoch\")\n",
        "  plt.ylabel(\"Cross Entropy losses\")\n",
        "\n",
        "  plt.plot(epochs[1:], training_losses[1:], label=\"Training Loss\")\n",
        "  plt.plot(epochs[1:], validation_losses[1:], label=\"Validation Loss\")\n",
        "  plt.legend()\n",
        "  \n",
        "  # We're not going to plot the first epoch, since the loss on the first epoch\n",
        "  # is often substantially greater than the loss for other epochs.\n",
        "  merged_losses = training_losses[1:] + validation_losses[1:]\n",
        "  highest_loss = max(merged_losses)\n",
        "  lowest_loss = min(merged_losses)\n",
        "  delta = highest_loss - lowest_loss\n",
        "  print(delta)\n",
        "\n",
        "  top_of_y_axis = highest_loss + (delta * 0.05)\n",
        "  bottom_of_y_axis = lowest_loss - (delta * 0.05)\n",
        "  plt.title('loss curve') \n",
        "  plt.ylim([bottom_of_y_axis, top_of_y_axis])\n",
        "  plt.show()  "
      ],
      "metadata": {
        "id": "kCVDIV3QThFV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_the_loss_curve(epochs, train_losses, validation_losses)"
      ],
      "metadata": {
        "id": "OUOT2OUi8D57"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_acc = test_model(model, testloader)\n",
        "print()\n",
        "print('accuracy on the test set: ', float(test_acc))"
      ],
      "metadata": {
        "id": "jyfdP1m3g9J6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}